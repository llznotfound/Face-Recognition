{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T06:50:00.486744Z",
     "start_time": "2020-06-16T06:49:58.183708Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "config = tf.ConfigProto()\n",
    "# 指定可见显卡\n",
    "# config.gpu_options.visible_device_list=\"1\"\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "#不满显存, 自适应分配\n",
    "config.gpu_options.allow_growth=True   \n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T06:50:03.299414Z",
     "start_time": "2020-06-16T06:50:03.151401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''ResNet50 model for Keras.\n",
    "# Reference:\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "Adapted from code contributed by BigMoyan.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow\n",
    "\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "\n",
    "\n",
    "def identity_block_preactive(input_tensor, kernel_size, filters, stage, block):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "  \n",
    "    x = BatchNormalization(axis=bn_axis)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters1, (3, 3),\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, (3,3),\n",
    "               padding='same',\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block_preactive(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        \n",
    "    x = Conv2D(filters1, (3, 3), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, (3,3), padding='same',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis)(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block_bottleneck(input_tensor, kernel_size, filters, stage, block):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "  \n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_bottleneck(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        \n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis)(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50_cifar_small(input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = (48,42,3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((1, 1))(img_input)\n",
    "    x = Conv2D(16, (3, 3), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = conv_block_bottleneck(x, 3, [16, 16, 64], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block_bottleneck(x, 3, [16, 16, 64], stage=2, block='b')\n",
    "    x = identity_block_bottleneck(x, 3, [16, 16, 64], stage=2, block='c')\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = conv_block_bottleneck(x, 3, [32, 32, 128], stage=3, block='a')\n",
    "    x = identity_block_bottleneck(x, 3, [32, 32, 128], stage=3, block='b')\n",
    "    x = identity_block_bottleneck(x, 3, [32, 32, 128], stage=3, block='c')\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = conv_block_bottleneck(x, 3, [64, 64, 256], stage=4, block='a')\n",
    "    x = identity_block_bottleneck(x, 3, [64, 64, 256], stage=4, block='b')\n",
    "    x = identity_block_bottleneck(x, 3, [64, 64, 256], stage=4, block='c')\n",
    "    \n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "\n",
    "    x = AveragePooling2D(pool_size=(block_shape[1], block_shape[2]),strides=(1, 1))(x)\n",
    "\n",
    "   \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T07:42:54.258463Z",
     "start_time": "2020-06-13T07:42:53.230564Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train -= mean_image\n",
    "x_test -= mean_image\n",
    "x_train = x_train/128\n",
    "x_test = x_test/128 \n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T06:52:39.759391Z",
     "start_time": "2020-06-16T06:52:39.730198Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(datapath, p):\n",
    "    sample_folder_list = os.listdir(datapath) ##各个样本的文件夹\n",
    "    sample_folder_list_dict = {} ##各个文件夹下的图片路径信息\n",
    "    train_dir_dict = {} ##用作训练的样本路径集合\n",
    "    test_dir_dict = {}##用作测试的样本路径集合\n",
    "\n",
    "    for folder in sample_folder_list:\n",
    "        sample_folder_list_dict[folder] = os.listdir(datapath+folder)\n",
    "        train_dir_dict[folder] = random.sample(sample_folder_list_dict[folder], p)\n",
    "        test_dir_dict[folder] = list(set(sample_folder_list_dict[folder])-set(train_dir_dict[folder]))\n",
    "\n",
    "    train_label = []\n",
    "    train_data = []\n",
    "\n",
    "    test_label = []\n",
    "    test_data = []\n",
    "\n",
    "    for key in train_dir_dict:\n",
    "        for path in train_dir_dict[key]:\n",
    "            train_label.append(min(int(key[-2:])-1, 37))\n",
    "            img = cv2.imread(datapath+key+'/'+path)\n",
    "            img = cv2.resize(img, (42, 48))\n",
    "            train_data.append(img)\n",
    "        \n",
    "        for path in test_dir_dict[key]:\n",
    "            test_label.append(min(int(key[-2:])-1, 37))\n",
    "            img = cv2.imread(datapath+key+'/'+path)\n",
    "            img = cv2.resize(img, (42, 48))\n",
    "            test_data.append(img)\n",
    "\n",
    "    return train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T07:24:14.379432Z",
     "start_time": "2020-06-16T07:24:14.004875Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "datapath = '/root/zhb/Documents/PR/data/' \n",
    "train_data, train_label, test_data, test_label = split_dataset(datapath, 30)\n",
    "train_data = np.asarray(train_data) / 255 - 0.5\n",
    "train_label = np.asarray(train_label) \n",
    "test_data = np.asarray(test_data) / 255 - 0.5\n",
    "test_label = np.asarray(test_label)\n",
    "train_label = keras.utils.to_categorical(train_label, 38)\n",
    "test_label = keras.utils.to_categorical(test_label, 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T07:46:29.046664Z",
     "start_time": "2020-06-16T07:24:15.404959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 24, 21, 16)\n",
      "(None, 24, 21, 64)\n",
      "(None, 12, 11, 128)\n",
      "(None, 6, 6, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/zhb/conda/Anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=17, validation_data=(array([[[..., epochs=1000, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 18s 1s/step - loss: 4.0917 - acc: 0.0515 - val_loss: 4.6570 - val_acc: 0.0361\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 3.9148 - acc: 0.0539 - val_loss: 5.5584 - val_acc: 0.0353\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 3.7863 - acc: 0.0895 - val_loss: 5.1273 - val_acc: 0.0541\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 3.7689 - acc: 0.0806 - val_loss: 4.3040 - val_acc: 0.0481\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 3.6892 - acc: 0.1022 - val_loss: 5.5044 - val_acc: 0.0541\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 3.6332 - acc: 0.1121 - val_loss: 6.2167 - val_acc: 0.0414\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 3.5792 - acc: 0.1094 - val_loss: 11.9842 - val_acc: 0.0421\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 3.4112 - acc: 0.1670 - val_loss: 10.3535 - val_acc: 0.0594\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 3.4533 - acc: 0.1581 - val_loss: 9.1040 - val_acc: 0.0662\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 3.3104 - acc: 0.1589 - val_loss: 7.5167 - val_acc: 0.0504\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 3.2388 - acc: 0.1934 - val_loss: 7.4378 - val_acc: 0.0519\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 3.1502 - acc: 0.2288 - val_loss: 5.0988 - val_acc: 0.0850\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 3.1517 - acc: 0.2014 - val_loss: 6.8651 - val_acc: 0.0571\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 3.0386 - acc: 0.2410 - val_loss: 7.0752 - val_acc: 0.0865\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 2.9928 - acc: 0.2716 - val_loss: 5.9700 - val_acc: 0.0714\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 2.9010 - acc: 0.2748 - val_loss: 5.6481 - val_acc: 0.1038\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.8830 - acc: 0.2708 - val_loss: 5.2555 - val_acc: 0.0872\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 2.7289 - acc: 0.3131 - val_loss: 6.6425 - val_acc: 0.0880\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 2.6935 - acc: 0.3088 - val_loss: 5.0916 - val_acc: 0.1376\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 2.6440 - acc: 0.3302 - val_loss: 5.3866 - val_acc: 0.1361\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 2.4754 - acc: 0.3784 - val_loss: 4.7206 - val_acc: 0.1346\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 2.4743 - acc: 0.3720 - val_loss: 5.1765 - val_acc: 0.1466\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 2.4044 - acc: 0.4114 - val_loss: 4.5878 - val_acc: 0.1677\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 2.2838 - acc: 0.4601 - val_loss: 4.3881 - val_acc: 0.1534\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 2.2365 - acc: 0.4524 - val_loss: 3.3057 - val_acc: 0.2383\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 2.2515 - acc: 0.4449 - val_loss: 4.5184 - val_acc: 0.2023\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 2.1284 - acc: 0.4695 - val_loss: 5.9086 - val_acc: 0.1271\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.9877 - acc: 0.5127 - val_loss: 5.9724 - val_acc: 0.1759\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 2.0082 - acc: 0.5221 - val_loss: 3.9796 - val_acc: 0.2158\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 1.8763 - acc: 0.5451 - val_loss: 4.2083 - val_acc: 0.2474\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.8063 - acc: 0.5935 - val_loss: 5.8997 - val_acc: 0.1842\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.8325 - acc: 0.5591 - val_loss: 5.4613 - val_acc: 0.2308\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 1.7533 - acc: 0.5862 - val_loss: 2.5283 - val_acc: 0.4203\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 1.7034 - acc: 0.5865 - val_loss: 2.5569 - val_acc: 0.4256\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 1.6707 - acc: 0.5850 - val_loss: 5.5632 - val_acc: 0.2331\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.5664 - acc: 0.6346 - val_loss: 4.4098 - val_acc: 0.2722\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 1.4901 - acc: 0.6572 - val_loss: 2.6588 - val_acc: 0.4023\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.4323 - acc: 0.6683 - val_loss: 7.0313 - val_acc: 0.2466\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 1.4309 - acc: 0.6844 - val_loss: 7.7664 - val_acc: 0.1947\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 1.3648 - acc: 0.7002 - val_loss: 5.7883 - val_acc: 0.2759\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 1.2646 - acc: 0.7279 - val_loss: 4.8473 - val_acc: 0.3571\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 1.1247 - acc: 0.7817 - val_loss: 3.2103 - val_acc: 0.4293\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 1.1281 - acc: 0.7710 - val_loss: 3.3476 - val_acc: 0.4602\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 1.1271 - acc: 0.7758 - val_loss: 1.9977 - val_acc: 0.5556\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 1.1024 - acc: 0.7943 - val_loss: 2.1228 - val_acc: 0.5429\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 1.0408 - acc: 0.8145 - val_loss: 1.5506 - val_acc: 0.6414\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 1.0617 - acc: 0.7970 - val_loss: 2.2434 - val_acc: 0.5504\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 1.0538 - acc: 0.8076 - val_loss: 1.8276 - val_acc: 0.5917\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 1.0460 - acc: 0.8124 - val_loss: 1.4007 - val_acc: 0.7008\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.0686 - acc: 0.7968 - val_loss: 1.3680 - val_acc: 0.7195\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 1.0242 - acc: 0.8271 - val_loss: 1.4309 - val_acc: 0.6985\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 1.0056 - acc: 0.8236 - val_loss: 1.4397 - val_acc: 0.6947\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 1.0236 - acc: 0.8161 - val_loss: 1.7099 - val_acc: 0.6376\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 1.0001 - acc: 0.8164 - val_loss: 1.3514 - val_acc: 0.7241\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.9994 - acc: 0.8318 - val_loss: 1.6153 - val_acc: 0.6519\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.0170 - acc: 0.8160 - val_loss: 1.3530 - val_acc: 0.7248\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 1.0143 - acc: 0.8117 - val_loss: 1.3520 - val_acc: 0.7188\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.9998 - acc: 0.8181 - val_loss: 1.4950 - val_acc: 0.6714\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.9756 - acc: 0.8196 - val_loss: 1.4549 - val_acc: 0.6895\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.1583 - acc: 0.7562 - val_loss: 4.5015 - val_acc: 0.3962\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 1.2508 - acc: 0.7286 - val_loss: 2.7021 - val_acc: 0.4504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 1.2655 - acc: 0.7304 - val_loss: 4.1699 - val_acc: 0.2947\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 1.2006 - acc: 0.7303 - val_loss: 7.0708 - val_acc: 0.2038\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 1.2014 - acc: 0.7288 - val_loss: 4.3060 - val_acc: 0.3045\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 1.1877 - acc: 0.7346 - val_loss: 3.9608 - val_acc: 0.3308\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 1.0879 - acc: 0.7579 - val_loss: 3.2462 - val_acc: 0.3744\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 1.0563 - acc: 0.7879 - val_loss: 2.9787 - val_acc: 0.4060\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 1.0083 - acc: 0.8091 - val_loss: 5.3494 - val_acc: 0.3827\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 1.0011 - acc: 0.8097 - val_loss: 2.5868 - val_acc: 0.4827\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.8783 - acc: 0.8476 - val_loss: 2.1440 - val_acc: 0.5421\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.8225 - acc: 0.8729 - val_loss: 2.0721 - val_acc: 0.5571\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 2s 120ms/step - loss: 0.7704 - acc: 0.8910 - val_loss: 1.8371 - val_acc: 0.6286\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.7422 - acc: 0.9044 - val_loss: 1.6864 - val_acc: 0.6436\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.7188 - acc: 0.9063 - val_loss: 1.5962 - val_acc: 0.6677\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.7317 - acc: 0.9144 - val_loss: 1.3265 - val_acc: 0.7211\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.7435 - acc: 0.9021 - val_loss: 1.2086 - val_acc: 0.7617\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.7506 - acc: 0.9039 - val_loss: 1.2926 - val_acc: 0.7451\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.7218 - acc: 0.9100 - val_loss: 1.7262 - val_acc: 0.6602\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 0.7115 - acc: 0.9077 - val_loss: 1.3036 - val_acc: 0.7286\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.7069 - acc: 0.9109 - val_loss: 1.2049 - val_acc: 0.7654\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.6946 - acc: 0.9158 - val_loss: 1.1644 - val_acc: 0.7692\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.7163 - acc: 0.9024 - val_loss: 1.1050 - val_acc: 0.7940\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.6983 - acc: 0.9017 - val_loss: 1.1101 - val_acc: 0.7880\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.6883 - acc: 0.9177 - val_loss: 1.1947 - val_acc: 0.7759\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.6625 - acc: 0.9243 - val_loss: 1.0972 - val_acc: 0.7962\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.6835 - acc: 0.9216 - val_loss: 1.1250 - val_acc: 0.7820\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.6594 - acc: 0.9187 - val_loss: 1.1099 - val_acc: 0.7917\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.6598 - acc: 0.9257 - val_loss: 1.0783 - val_acc: 0.7955\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.6712 - acc: 0.9210 - val_loss: 1.1753 - val_acc: 0.7744\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 2s 120ms/step - loss: 0.6442 - acc: 0.9311 - val_loss: 1.0662 - val_acc: 0.8000\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.6626 - acc: 0.9182 - val_loss: 1.1214 - val_acc: 0.7910\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.6567 - acc: 0.9141 - val_loss: 1.1157 - val_acc: 0.7887\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.6223 - acc: 0.9403 - val_loss: 1.2660 - val_acc: 0.7459\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.6409 - acc: 0.9315 - val_loss: 1.1085 - val_acc: 0.7992\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.6244 - acc: 0.9328 - val_loss: 1.0920 - val_acc: 0.8008\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.6484 - acc: 0.9271 - val_loss: 1.0745 - val_acc: 0.7977\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.6240 - acc: 0.9371 - val_loss: 1.0870 - val_acc: 0.8045\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.6104 - acc: 0.9451 - val_loss: 1.1505 - val_acc: 0.7962\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.6371 - acc: 0.9273 - val_loss: 1.0960 - val_acc: 0.8083\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.6286 - acc: 0.9352 - val_loss: 1.0776 - val_acc: 0.8120\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.6261 - acc: 0.9269 - val_loss: 1.3147 - val_acc: 0.7489\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.6301 - acc: 0.9304 - val_loss: 1.1251 - val_acc: 0.8038\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.6269 - acc: 0.9336 - val_loss: 1.0418 - val_acc: 0.8150\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.6140 - acc: 0.9334 - val_loss: 1.5481 - val_acc: 0.7083\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.6175 - acc: 0.9344 - val_loss: 1.2126 - val_acc: 0.7699\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.6049 - acc: 0.9328 - val_loss: 1.2094 - val_acc: 0.7797\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.6101 - acc: 0.9385 - val_loss: 1.1698 - val_acc: 0.7992\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 0.6250 - acc: 0.9314 - val_loss: 1.3031 - val_acc: 0.7549\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.6148 - acc: 0.9347 - val_loss: 1.0254 - val_acc: 0.8263\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.6165 - acc: 0.9390 - val_loss: 1.0025 - val_acc: 0.8263\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.5920 - acc: 0.9434 - val_loss: 1.1461 - val_acc: 0.8068\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.5779 - acc: 0.9481 - val_loss: 0.9921 - val_acc: 0.8286\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.6060 - acc: 0.9323 - val_loss: 1.0746 - val_acc: 0.8173\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.5861 - acc: 0.9389 - val_loss: 1.3677 - val_acc: 0.7526\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.6110 - acc: 0.9398 - val_loss: 1.1603 - val_acc: 0.7910\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.5711 - acc: 0.9433 - val_loss: 1.1048 - val_acc: 0.8083\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.5930 - acc: 0.9245 - val_loss: 1.1437 - val_acc: 0.8030\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5731 - acc: 0.9536 - val_loss: 1.0223 - val_acc: 0.8218\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.6119 - acc: 0.9392 - val_loss: 0.9997 - val_acc: 0.8338\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5946 - acc: 0.9378 - val_loss: 1.3002 - val_acc: 0.7496\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5935 - acc: 0.9411 - val_loss: 1.1446 - val_acc: 0.7902\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.5689 - acc: 0.9519 - val_loss: 1.0826 - val_acc: 0.8128\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5836 - acc: 0.9442 - val_loss: 1.0056 - val_acc: 0.8293\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.5642 - acc: 0.9571 - val_loss: 1.0701 - val_acc: 0.8105\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5836 - acc: 0.9401 - val_loss: 1.0722 - val_acc: 0.8053\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 0.5594 - acc: 0.9553 - val_loss: 0.9720 - val_acc: 0.8376\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.5801 - acc: 0.9467 - val_loss: 1.0077 - val_acc: 0.8316\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5645 - acc: 0.9472 - val_loss: 0.9882 - val_acc: 0.8331\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.5448 - acc: 0.9549 - val_loss: 0.9749 - val_acc: 0.8361\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5606 - acc: 0.9490 - val_loss: 1.0131 - val_acc: 0.8361\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.5540 - acc: 0.9595 - val_loss: 1.1393 - val_acc: 0.8008\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5759 - acc: 0.9394 - val_loss: 1.1058 - val_acc: 0.8128\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.5500 - acc: 0.9610 - val_loss: 1.0228 - val_acc: 0.8368\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.5462 - acc: 0.9578 - val_loss: 1.0095 - val_acc: 0.8338\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.5426 - acc: 0.9584 - val_loss: 1.0530 - val_acc: 0.8083\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.5412 - acc: 0.9483 - val_loss: 0.9943 - val_acc: 0.8429\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.5404 - acc: 0.9663 - val_loss: 1.1087 - val_acc: 0.7955\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.5358 - acc: 0.9589 - val_loss: 0.9753 - val_acc: 0.8368\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.5431 - acc: 0.9558 - val_loss: 0.9515 - val_acc: 0.8361\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.5410 - acc: 0.9516 - val_loss: 1.0035 - val_acc: 0.8233\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.5481 - acc: 0.9580 - val_loss: 1.1258 - val_acc: 0.7917\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 2s 99ms/step - loss: 0.5250 - acc: 0.9597 - val_loss: 1.1962 - val_acc: 0.7729\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.5568 - acc: 0.9536 - val_loss: 1.0335 - val_acc: 0.8271\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 0.5350 - acc: 0.9541 - val_loss: 0.9414 - val_acc: 0.8571\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.5354 - acc: 0.9531 - val_loss: 0.9571 - val_acc: 0.8556\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5272 - acc: 0.9611 - val_loss: 0.9250 - val_acc: 0.8549\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5168 - acc: 0.9584 - val_loss: 1.1518 - val_acc: 0.8008\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5262 - acc: 0.9630 - val_loss: 0.9699 - val_acc: 0.8346\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.5219 - acc: 0.9566 - val_loss: 1.1255 - val_acc: 0.7917\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.5068 - acc: 0.9740 - val_loss: 1.0408 - val_acc: 0.8218\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.5158 - acc: 0.9571 - val_loss: 0.9352 - val_acc: 0.8549\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5261 - acc: 0.9529 - val_loss: 0.9561 - val_acc: 0.8376\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.5310 - acc: 0.9610 - val_loss: 1.1405 - val_acc: 0.8135\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5318 - acc: 0.9474 - val_loss: 0.9517 - val_acc: 0.8466\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.5231 - acc: 0.9615 - val_loss: 0.9963 - val_acc: 0.8519\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.5336 - acc: 0.9578 - val_loss: 0.9669 - val_acc: 0.8481\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4989 - acc: 0.9650 - val_loss: 0.9775 - val_acc: 0.8391\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 0.5186 - acc: 0.9566 - val_loss: 0.9585 - val_acc: 0.8421\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 2s 100ms/step - loss: 0.5146 - acc: 0.9575 - val_loss: 1.0331 - val_acc: 0.8248\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.5125 - acc: 0.9633 - val_loss: 0.9183 - val_acc: 0.8647\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4942 - acc: 0.9617 - val_loss: 0.9185 - val_acc: 0.8602\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.5016 - acc: 0.9667 - val_loss: 0.9274 - val_acc: 0.8639\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.5040 - acc: 0.9706 - val_loss: 0.9292 - val_acc: 0.8594\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.5128 - acc: 0.9619 - val_loss: 0.9814 - val_acc: 0.8331\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4845 - acc: 0.9718 - val_loss: 0.9940 - val_acc: 0.8353\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.5138 - acc: 0.9541 - val_loss: 0.9706 - val_acc: 0.8556\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.5028 - acc: 0.9641 - val_loss: 0.9631 - val_acc: 0.8406\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4938 - acc: 0.9706 - val_loss: 1.0700 - val_acc: 0.8143\n",
      "Epoch 169/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4981 - acc: 0.9676 - val_loss: 0.9344 - val_acc: 0.8541\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4921 - acc: 0.9665 - val_loss: 0.9382 - val_acc: 0.8594\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4833 - acc: 0.9731 - val_loss: 0.9455 - val_acc: 0.8549\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.4965 - acc: 0.9733 - val_loss: 1.2899 - val_acc: 0.7767\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4834 - acc: 0.9731 - val_loss: 1.0470 - val_acc: 0.8331\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4686 - acc: 0.9770 - val_loss: 0.9401 - val_acc: 0.8519\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4703 - acc: 0.9823 - val_loss: 0.9723 - val_acc: 0.8602\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4890 - acc: 0.9675 - val_loss: 0.9685 - val_acc: 0.8579\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.4789 - acc: 0.9769 - val_loss: 1.0169 - val_acc: 0.8496\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4863 - acc: 0.9685 - val_loss: 1.0557 - val_acc: 0.8211\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4830 - acc: 0.9709 - val_loss: 1.0106 - val_acc: 0.8383\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 0.4830 - acc: 0.9733 - val_loss: 0.9980 - val_acc: 0.8444\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4690 - acc: 0.9761 - val_loss: 1.0636 - val_acc: 0.8068\n",
      "Epoch 182/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 106ms/step - loss: 0.4881 - acc: 0.9721 - val_loss: 0.9478 - val_acc: 0.8436\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4966 - acc: 0.9649 - val_loss: 0.9326 - val_acc: 0.8534\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4807 - acc: 0.9716 - val_loss: 0.9157 - val_acc: 0.8586\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4848 - acc: 0.9702 - val_loss: 0.9318 - val_acc: 0.8459\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4771 - acc: 0.9773 - val_loss: 0.9068 - val_acc: 0.8624\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4976 - acc: 0.9630 - val_loss: 0.9493 - val_acc: 0.8556\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4989 - acc: 0.9601 - val_loss: 0.9188 - val_acc: 0.8564\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.4694 - acc: 0.9752 - val_loss: 0.9178 - val_acc: 0.8617\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4757 - acc: 0.9748 - val_loss: 0.9202 - val_acc: 0.8564\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4733 - acc: 0.9700 - val_loss: 0.9101 - val_acc: 0.8677\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 0.4656 - acc: 0.9759 - val_loss: 0.9144 - val_acc: 0.8556\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4886 - acc: 0.9678 - val_loss: 1.1334 - val_acc: 0.8090\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4913 - acc: 0.9676 - val_loss: 1.0668 - val_acc: 0.8353\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.4722 - acc: 0.9777 - val_loss: 1.3136 - val_acc: 0.7812\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4703 - acc: 0.9706 - val_loss: 0.9855 - val_acc: 0.8602\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4887 - acc: 0.9597 - val_loss: 0.9685 - val_acc: 0.8571\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 0.4620 - acc: 0.9770 - val_loss: 0.9755 - val_acc: 0.8586\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4577 - acc: 0.9789 - val_loss: 0.9770 - val_acc: 0.8534\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4719 - acc: 0.9736 - val_loss: 0.9269 - val_acc: 0.8647\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4609 - acc: 0.9788 - val_loss: 0.9176 - val_acc: 0.8654\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4722 - acc: 0.9748 - val_loss: 1.3423 - val_acc: 0.7932\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.4612 - acc: 0.9731 - val_loss: 0.9773 - val_acc: 0.8346\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4642 - acc: 0.9736 - val_loss: 0.9340 - val_acc: 0.8617\n",
      "Epoch 205/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.4578 - acc: 0.9796 - val_loss: 0.9033 - val_acc: 0.8639\n",
      "Epoch 206/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4572 - acc: 0.9807 - val_loss: 0.9438 - val_acc: 0.8489\n",
      "Epoch 207/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4585 - acc: 0.9744 - val_loss: 0.9419 - val_acc: 0.8699\n",
      "Epoch 208/1000\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 0.4621 - acc: 0.9711 - val_loss: 0.9709 - val_acc: 0.8526\n",
      "Epoch 209/1000\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 0.4576 - acc: 0.9746 - val_loss: 1.3036 - val_acc: 0.7932\n",
      "Epoch 210/1000\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 0.4551 - acc: 0.9798 - val_loss: 1.0790 - val_acc: 0.8338\n",
      "Epoch 211/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4412 - acc: 0.9830 - val_loss: 1.2573 - val_acc: 0.7917\n",
      "Epoch 212/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4510 - acc: 0.9777 - val_loss: 1.1682 - val_acc: 0.8188\n",
      "Epoch 213/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4500 - acc: 0.9798 - val_loss: 1.0781 - val_acc: 0.8368\n",
      "Epoch 214/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4480 - acc: 0.9803 - val_loss: 1.0065 - val_acc: 0.8579\n",
      "Epoch 215/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4574 - acc: 0.9738 - val_loss: 0.9812 - val_acc: 0.8617\n",
      "Epoch 216/1000\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 0.4628 - acc: 0.9738 - val_loss: 0.9298 - val_acc: 0.8729\n",
      "Epoch 217/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4488 - acc: 0.9853 - val_loss: 1.0347 - val_acc: 0.8391\n",
      "Epoch 218/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4506 - acc: 0.9786 - val_loss: 0.9806 - val_acc: 0.8429\n",
      "Epoch 219/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4343 - acc: 0.9858 - val_loss: 0.8901 - val_acc: 0.8782\n",
      "Epoch 220/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4341 - acc: 0.9871 - val_loss: 0.8862 - val_acc: 0.8797\n",
      "Epoch 221/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4457 - acc: 0.9814 - val_loss: 0.9259 - val_acc: 0.8662\n",
      "Epoch 222/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4402 - acc: 0.9834 - val_loss: 0.8838 - val_acc: 0.8669\n",
      "Epoch 223/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4511 - acc: 0.9738 - val_loss: 0.9910 - val_acc: 0.8586\n",
      "Epoch 224/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4555 - acc: 0.9761 - val_loss: 0.8918 - val_acc: 0.8662\n",
      "Epoch 225/1000\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 0.4312 - acc: 0.9860 - val_loss: 0.9864 - val_acc: 0.8361\n",
      "Epoch 226/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4439 - acc: 0.9786 - val_loss: 0.9335 - val_acc: 0.8639\n",
      "Epoch 227/1000\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 0.4233 - acc: 0.9908 - val_loss: 1.2295 - val_acc: 0.8090\n",
      "Epoch 228/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4410 - acc: 0.9761 - val_loss: 1.0464 - val_acc: 0.8406\n",
      "Epoch 229/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4430 - acc: 0.9798 - val_loss: 0.9488 - val_acc: 0.8586\n",
      "Epoch 230/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4419 - acc: 0.9796 - val_loss: 0.9358 - val_acc: 0.8624\n",
      "Epoch 231/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4348 - acc: 0.9821 - val_loss: 0.9288 - val_acc: 0.8489\n",
      "Epoch 232/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4302 - acc: 0.9805 - val_loss: 0.9215 - val_acc: 0.8481\n",
      "Epoch 233/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4412 - acc: 0.9775 - val_loss: 0.9150 - val_acc: 0.8556\n",
      "Epoch 234/1000\n",
      "17/17 [==============================] - 2s 128ms/step - loss: 0.4345 - acc: 0.9786 - val_loss: 0.9597 - val_acc: 0.8534\n",
      "Epoch 235/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4370 - acc: 0.9789 - val_loss: 0.9836 - val_acc: 0.8466\n",
      "Epoch 236/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4403 - acc: 0.9807 - val_loss: 1.0126 - val_acc: 0.8376\n",
      "Epoch 237/1000\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.4281 - acc: 0.9814 - val_loss: 0.9402 - val_acc: 0.8662\n",
      "Epoch 238/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.4298 - acc: 0.9816 - val_loss: 1.1725 - val_acc: 0.8173\n",
      "Epoch 239/1000\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 0.4369 - acc: 0.9757 - val_loss: 1.4047 - val_acc: 0.7782\n",
      "Epoch 240/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4312 - acc: 0.9798 - val_loss: 0.9622 - val_acc: 0.8632\n",
      "Epoch 241/1000\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 0.4212 - acc: 0.9807 - val_loss: 0.9437 - val_acc: 0.8654\n",
      "Epoch 242/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4247 - acc: 0.9823 - val_loss: 1.0976 - val_acc: 0.8301\n",
      "Epoch 243/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4351 - acc: 0.9788 - val_loss: 0.9480 - val_acc: 0.8662\n",
      "Epoch 244/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4326 - acc: 0.9777 - val_loss: 0.9063 - val_acc: 0.8602\n",
      "Epoch 245/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4433 - acc: 0.9777 - val_loss: 0.9958 - val_acc: 0.8594\n",
      "Epoch 246/1000\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.4255 - acc: 0.9844 - val_loss: 1.0986 - val_acc: 0.8361\n",
      "Epoch 247/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4296 - acc: 0.9845 - val_loss: 1.0566 - val_acc: 0.8466\n",
      "Epoch 248/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4248 - acc: 0.9823 - val_loss: 1.0327 - val_acc: 0.8526\n",
      "Epoch 249/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4357 - acc: 0.9832 - val_loss: 1.0828 - val_acc: 0.8391\n",
      "Epoch 250/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4404 - acc: 0.9742 - val_loss: 0.8746 - val_acc: 0.8865\n",
      "Epoch 251/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4290 - acc: 0.9807 - val_loss: 0.9195 - val_acc: 0.8579\n",
      "Epoch 252/1000\n",
      "17/17 [==============================] - 2s 119ms/step - loss: 0.4300 - acc: 0.9801 - val_loss: 0.9835 - val_acc: 0.8414\n",
      "Epoch 253/1000\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.4235 - acc: 0.9816 - val_loss: 0.9064 - val_acc: 0.8669\n",
      "Epoch 254/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4322 - acc: 0.9830 - val_loss: 0.8864 - val_acc: 0.8639\n",
      "Epoch 255/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4110 - acc: 0.9897 - val_loss: 0.8861 - val_acc: 0.8744\n",
      "Epoch 256/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4192 - acc: 0.9860 - val_loss: 1.1437 - val_acc: 0.8226\n",
      "Epoch 257/1000\n",
      "17/17 [==============================] - 2s 115ms/step - loss: 0.4325 - acc: 0.9746 - val_loss: 0.8940 - val_acc: 0.8812\n",
      "Epoch 258/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4054 - acc: 0.9880 - val_loss: 0.8961 - val_acc: 0.8737\n",
      "Epoch 259/1000\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.4357 - acc: 0.9752 - val_loss: 0.9751 - val_acc: 0.8481\n",
      "Epoch 260/1000\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.4091 - acc: 0.9888 - val_loss: 0.9265 - val_acc: 0.8722\n",
      "Epoch 261/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4193 - acc: 0.9869 - val_loss: 0.8919 - val_acc: 0.8737\n",
      "Epoch 262/1000\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 0.4142 - acc: 0.9880 - val_loss: 0.9073 - val_acc: 0.8805\n",
      "Epoch 263/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4136 - acc: 0.9834 - val_loss: 0.9329 - val_acc: 0.8669\n",
      "Epoch 264/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4138 - acc: 0.9886 - val_loss: 0.8924 - val_acc: 0.8677\n",
      "Epoch 265/1000\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.4274 - acc: 0.9843 - val_loss: 1.0423 - val_acc: 0.8549\n",
      "Epoch 266/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4170 - acc: 0.9849 - val_loss: 0.8583 - val_acc: 0.8820\n",
      "Epoch 267/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4078 - acc: 0.9888 - val_loss: 0.9488 - val_acc: 0.8677\n",
      "Epoch 268/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4151 - acc: 0.9832 - val_loss: 1.3332 - val_acc: 0.7865\n",
      "Epoch 269/1000\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.4168 - acc: 0.9842 - val_loss: 0.9535 - val_acc: 0.8617\n",
      "Epoch 270/1000\n",
      "17/17 [==============================] - 2s 116ms/step - loss: 0.4082 - acc: 0.9844 - val_loss: 1.0623 - val_acc: 0.8383\n",
      "Epoch 271/1000\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.4126 - acc: 0.9853 - val_loss: 0.9170 - val_acc: 0.8571\n",
      "Epoch 272/1000\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4134 - acc: 0.9842 - val_loss: 0.9340 - val_acc: 0.8489\n",
      "Epoch 273/1000\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.4175 - acc: 0.9834 - val_loss: 0.9581 - val_acc: 0.8534\n",
      "Epoch 274/1000\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.4132 - acc: 0.9869 - val_loss: 0.9216 - val_acc: 0.8699\n",
      "Epoch 275/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4018 - acc: 0.9908 - val_loss: 0.9369 - val_acc: 0.8684\n",
      "Epoch 276/1000\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4216 - acc: 0.9819 - val_loss: 0.9255 - val_acc: 0.8662\n",
      "Epoch 277/1000\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.4094 - acc: 0.9874 - val_loss: 1.0150 - val_acc: 0.8534\n",
      "Epoch 278/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.4060 - acc: 0.9878 - val_loss: 0.9124 - val_acc: 0.8677\n",
      "Epoch 279/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.4097 - acc: 0.9893 - val_loss: 0.9018 - val_acc: 0.8850\n",
      "Epoch 280/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.4103 - acc: 0.9862 - val_loss: 1.2022 - val_acc: 0.8173\n",
      "Epoch 281/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3978 - acc: 0.9904 - val_loss: 1.1067 - val_acc: 0.8263\n",
      "Epoch 282/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.4076 - acc: 0.9897 - val_loss: 0.9890 - val_acc: 0.8647\n",
      "Epoch 283/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.4089 - acc: 0.9826 - val_loss: 0.8737 - val_acc: 0.8805\n",
      "Epoch 284/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.4063 - acc: 0.9862 - val_loss: 0.8701 - val_acc: 0.8797\n",
      "Epoch 285/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4078 - acc: 0.9832 - val_loss: 0.8916 - val_acc: 0.8865\n",
      "Epoch 286/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.4006 - acc: 0.9878 - val_loss: 1.3366 - val_acc: 0.7902\n",
      "Epoch 287/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.4014 - acc: 0.9871 - val_loss: 0.9351 - val_acc: 0.8699\n",
      "Epoch 288/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4134 - acc: 0.9847 - val_loss: 1.0406 - val_acc: 0.8526\n",
      "Epoch 289/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.4025 - acc: 0.9899 - val_loss: 0.8810 - val_acc: 0.8774\n",
      "Epoch 290/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4042 - acc: 0.9851 - val_loss: 0.8674 - val_acc: 0.8774\n",
      "Epoch 291/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3990 - acc: 0.9890 - val_loss: 0.9473 - val_acc: 0.8571\n",
      "Epoch 292/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.4013 - acc: 0.9880 - val_loss: 0.9230 - val_acc: 0.8564\n",
      "Epoch 293/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.4005 - acc: 0.9851 - val_loss: 1.0267 - val_acc: 0.8271\n",
      "Epoch 294/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3938 - acc: 0.9908 - val_loss: 0.8756 - val_acc: 0.8812\n",
      "Epoch 295/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.4123 - acc: 0.9830 - val_loss: 0.8529 - val_acc: 0.8910\n",
      "Epoch 296/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.4056 - acc: 0.9862 - val_loss: 0.9225 - val_acc: 0.8820\n",
      "Epoch 297/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4034 - acc: 0.9899 - val_loss: 0.9509 - val_acc: 0.8444\n",
      "Epoch 298/1000\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 0.3903 - acc: 0.9895 - val_loss: 0.9278 - val_acc: 0.8541\n",
      "Epoch 299/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3849 - acc: 0.9936 - val_loss: 0.8676 - val_acc: 0.8789\n",
      "Epoch 300/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.4001 - acc: 0.9880 - val_loss: 0.9108 - val_acc: 0.8669\n",
      "Epoch 301/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.4002 - acc: 0.9847 - val_loss: 0.9543 - val_acc: 0.8759\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4069 - acc: 0.9828 - val_loss: 0.9970 - val_acc: 0.8564\n",
      "Epoch 303/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.4113 - acc: 0.9768 - val_loss: 1.1613 - val_acc: 0.8226\n",
      "Epoch 304/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3992 - acc: 0.9847 - val_loss: 0.9236 - val_acc: 0.8714\n",
      "Epoch 305/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.4015 - acc: 0.9871 - val_loss: 1.0395 - val_acc: 0.8526\n",
      "Epoch 306/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.4083 - acc: 0.9807 - val_loss: 0.9492 - val_acc: 0.8609\n",
      "Epoch 307/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3955 - acc: 0.9899 - val_loss: 0.9272 - val_acc: 0.8632\n",
      "Epoch 308/1000\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 0.3986 - acc: 0.9862 - val_loss: 1.2476 - val_acc: 0.7985\n",
      "Epoch 309/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3870 - acc: 0.9908 - val_loss: 0.8873 - val_acc: 0.8714\n",
      "Epoch 310/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3981 - acc: 0.9880 - val_loss: 1.2404 - val_acc: 0.8098\n",
      "Epoch 311/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3846 - acc: 0.9906 - val_loss: 0.9277 - val_acc: 0.8707\n",
      "Epoch 312/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3879 - acc: 0.9936 - val_loss: 0.8841 - val_acc: 0.8774\n",
      "Epoch 313/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3996 - acc: 0.9867 - val_loss: 0.9184 - val_acc: 0.8722\n",
      "Epoch 314/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3926 - acc: 0.9888 - val_loss: 0.9030 - val_acc: 0.8820\n",
      "Epoch 315/1000\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 0.3880 - acc: 0.9899 - val_loss: 0.9897 - val_acc: 0.8602\n",
      "Epoch 316/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.4006 - acc: 0.9880 - val_loss: 0.8896 - val_acc: 0.8789\n",
      "Epoch 317/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3958 - acc: 0.9878 - val_loss: 0.9348 - val_acc: 0.8586\n",
      "Epoch 318/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3894 - acc: 0.9932 - val_loss: 0.8668 - val_acc: 0.8872\n",
      "Epoch 319/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3906 - acc: 0.9880 - val_loss: 0.8737 - val_acc: 0.8835\n",
      "Epoch 320/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3958 - acc: 0.9884 - val_loss: 0.9565 - val_acc: 0.8549\n",
      "Epoch 321/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.4114 - acc: 0.9786 - val_loss: 0.9697 - val_acc: 0.8519\n",
      "Epoch 322/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3983 - acc: 0.9876 - val_loss: 0.9304 - val_acc: 0.8579\n",
      "Epoch 323/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3921 - acc: 0.9897 - val_loss: 0.9198 - val_acc: 0.8564\n",
      "Epoch 324/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3939 - acc: 0.9878 - val_loss: 0.9129 - val_acc: 0.8827\n",
      "Epoch 325/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.4016 - acc: 0.9862 - val_loss: 0.9090 - val_acc: 0.8654\n",
      "Epoch 326/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.4122 - acc: 0.9816 - val_loss: 0.9445 - val_acc: 0.8669\n",
      "Epoch 327/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3937 - acc: 0.9869 - val_loss: 1.0617 - val_acc: 0.8353\n",
      "Epoch 328/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3827 - acc: 0.9917 - val_loss: 0.9029 - val_acc: 0.8880\n",
      "Epoch 329/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3828 - acc: 0.9906 - val_loss: 0.8810 - val_acc: 0.8880\n",
      "Epoch 330/1000\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.3763 - acc: 0.9917 - val_loss: 0.8750 - val_acc: 0.8947\n",
      "Epoch 331/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3837 - acc: 0.9897 - val_loss: 1.4468 - val_acc: 0.7910\n",
      "Epoch 332/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3848 - acc: 0.9897 - val_loss: 0.9447 - val_acc: 0.8782\n",
      "Epoch 333/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3985 - acc: 0.9871 - val_loss: 1.0036 - val_acc: 0.8647\n",
      "Epoch 334/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3840 - acc: 0.9926 - val_loss: 0.9280 - val_acc: 0.8677\n",
      "Epoch 335/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3790 - acc: 0.9936 - val_loss: 0.8979 - val_acc: 0.8759\n",
      "Epoch 336/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3752 - acc: 0.9906 - val_loss: 0.9035 - val_acc: 0.8872\n",
      "Epoch 337/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3894 - acc: 0.9899 - val_loss: 1.0568 - val_acc: 0.8383\n",
      "Epoch 338/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3826 - acc: 0.9906 - val_loss: 0.8390 - val_acc: 0.8910\n",
      "Epoch 339/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3905 - acc: 0.9899 - val_loss: 0.8373 - val_acc: 0.8872\n",
      "Epoch 340/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3907 - acc: 0.9844 - val_loss: 0.8480 - val_acc: 0.8940\n",
      "Epoch 341/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3855 - acc: 0.9908 - val_loss: 1.1151 - val_acc: 0.8331\n",
      "Epoch 342/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3901 - acc: 0.9888 - val_loss: 0.8950 - val_acc: 0.8729\n",
      "Epoch 343/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3879 - acc: 0.9853 - val_loss: 0.9804 - val_acc: 0.8602\n",
      "Epoch 344/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3859 - acc: 0.9849 - val_loss: 0.8943 - val_acc: 0.8865\n",
      "Epoch 345/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3792 - acc: 0.9936 - val_loss: 0.8996 - val_acc: 0.8910\n",
      "Epoch 346/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3828 - acc: 0.9844 - val_loss: 0.9687 - val_acc: 0.8669\n",
      "Epoch 347/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3893 - acc: 0.9871 - val_loss: 0.8515 - val_acc: 0.8977\n",
      "Epoch 348/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3842 - acc: 0.9878 - val_loss: 1.6206 - val_acc: 0.7782\n",
      "Epoch 349/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3946 - acc: 0.9821 - val_loss: 1.1497 - val_acc: 0.8444\n",
      "Epoch 350/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3921 - acc: 0.9844 - val_loss: 1.1219 - val_acc: 0.8466\n",
      "Epoch 351/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3764 - acc: 0.9936 - val_loss: 1.3408 - val_acc: 0.8211\n",
      "Epoch 352/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3877 - acc: 0.9895 - val_loss: 1.1324 - val_acc: 0.8421\n",
      "Epoch 353/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3902 - acc: 0.9844 - val_loss: 0.8697 - val_acc: 0.8872\n",
      "Epoch 354/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3942 - acc: 0.9858 - val_loss: 1.4850 - val_acc: 0.7902\n",
      "Epoch 355/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.4001 - acc: 0.9825 - val_loss: 1.0023 - val_acc: 0.8662\n",
      "Epoch 356/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3795 - acc: 0.9897 - val_loss: 1.0749 - val_acc: 0.8564\n",
      "Epoch 357/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3848 - acc: 0.9825 - val_loss: 1.3267 - val_acc: 0.8105\n",
      "Epoch 358/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3763 - acc: 0.9917 - val_loss: 1.3813 - val_acc: 0.7887\n",
      "Epoch 359/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3871 - acc: 0.9878 - val_loss: 0.8990 - val_acc: 0.8842\n",
      "Epoch 360/1000\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 0.3981 - acc: 0.9842 - val_loss: 0.8678 - val_acc: 0.8767\n",
      "Epoch 361/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3820 - acc: 0.9917 - val_loss: 0.9602 - val_acc: 0.8519\n",
      "Epoch 362/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3872 - acc: 0.9860 - val_loss: 1.0890 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3712 - acc: 0.9917 - val_loss: 0.9969 - val_acc: 0.8684\n",
      "Epoch 364/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3806 - acc: 0.9888 - val_loss: 0.9848 - val_acc: 0.8451\n",
      "Epoch 365/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3824 - acc: 0.9899 - val_loss: 0.9950 - val_acc: 0.8496\n",
      "Epoch 366/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3809 - acc: 0.9904 - val_loss: 0.8601 - val_acc: 0.8962\n",
      "Epoch 367/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3761 - acc: 0.9915 - val_loss: 0.8593 - val_acc: 0.8902\n",
      "Epoch 368/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3729 - acc: 0.9888 - val_loss: 0.8296 - val_acc: 0.8970\n",
      "Epoch 369/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3736 - acc: 0.9917 - val_loss: 0.8568 - val_acc: 0.8895\n",
      "Epoch 370/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3774 - acc: 0.9878 - val_loss: 0.8404 - val_acc: 0.8902\n",
      "Epoch 371/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3907 - acc: 0.9851 - val_loss: 1.0566 - val_acc: 0.8368\n",
      "Epoch 372/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3824 - acc: 0.9915 - val_loss: 0.8665 - val_acc: 0.8827\n",
      "Epoch 373/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3824 - acc: 0.9908 - val_loss: 0.8490 - val_acc: 0.8842\n",
      "Epoch 374/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3890 - acc: 0.9860 - val_loss: 0.8710 - val_acc: 0.8902\n",
      "Epoch 375/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3789 - acc: 0.9897 - val_loss: 0.8645 - val_acc: 0.8992\n",
      "Epoch 376/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3732 - acc: 0.9926 - val_loss: 0.9731 - val_acc: 0.8662\n",
      "Epoch 377/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3624 - acc: 0.9963 - val_loss: 0.8742 - val_acc: 0.8812\n",
      "Epoch 378/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3790 - acc: 0.9908 - val_loss: 0.8714 - val_acc: 0.8767\n",
      "Epoch 379/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3785 - acc: 0.9890 - val_loss: 0.8569 - val_acc: 0.8880\n",
      "Epoch 380/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3652 - acc: 0.9954 - val_loss: 1.0181 - val_acc: 0.8429\n",
      "Epoch 381/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3657 - acc: 0.9932 - val_loss: 0.8850 - val_acc: 0.8759\n",
      "Epoch 382/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3749 - acc: 0.9926 - val_loss: 0.9662 - val_acc: 0.8759\n",
      "Epoch 383/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3690 - acc: 0.9906 - val_loss: 0.9151 - val_acc: 0.8692\n",
      "Epoch 384/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3688 - acc: 0.9908 - val_loss: 1.0050 - val_acc: 0.8511\n",
      "Epoch 385/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3705 - acc: 0.9936 - val_loss: 0.9590 - val_acc: 0.8602\n",
      "Epoch 386/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3638 - acc: 0.9952 - val_loss: 0.8769 - val_acc: 0.9000\n",
      "Epoch 387/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3693 - acc: 0.9926 - val_loss: 0.8658 - val_acc: 0.9008\n",
      "Epoch 388/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3804 - acc: 0.9869 - val_loss: 1.0584 - val_acc: 0.8579\n",
      "Epoch 389/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3708 - acc: 0.9917 - val_loss: 0.9249 - val_acc: 0.8812\n",
      "Epoch 390/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3626 - acc: 0.9926 - val_loss: 0.9395 - val_acc: 0.8684\n",
      "Epoch 391/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3661 - acc: 0.9926 - val_loss: 1.0800 - val_acc: 0.8436\n",
      "Epoch 392/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3710 - acc: 0.9897 - val_loss: 0.8980 - val_acc: 0.8759\n",
      "Epoch 393/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3611 - acc: 0.9945 - val_loss: 0.8535 - val_acc: 0.8895\n",
      "Epoch 394/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3710 - acc: 0.9934 - val_loss: 0.8939 - val_acc: 0.8714\n",
      "Epoch 395/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3772 - acc: 0.9917 - val_loss: 1.3903 - val_acc: 0.8098\n",
      "Epoch 396/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3708 - acc: 0.9915 - val_loss: 1.1383 - val_acc: 0.8436\n",
      "Epoch 397/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3752 - acc: 0.9881 - val_loss: 1.0697 - val_acc: 0.8504\n",
      "Epoch 398/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3828 - acc: 0.9878 - val_loss: 1.1489 - val_acc: 0.8361\n",
      "Epoch 399/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3579 - acc: 0.9970 - val_loss: 0.9090 - val_acc: 0.8865\n",
      "Epoch 400/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3628 - acc: 0.9954 - val_loss: 1.0595 - val_acc: 0.8617\n",
      "Epoch 401/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3768 - acc: 0.9842 - val_loss: 0.8581 - val_acc: 0.9030\n",
      "Epoch 402/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3727 - acc: 0.9890 - val_loss: 0.9463 - val_acc: 0.8835\n",
      "Epoch 403/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3692 - acc: 0.9924 - val_loss: 0.8842 - val_acc: 0.8797\n",
      "Epoch 404/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3654 - acc: 0.9926 - val_loss: 1.1410 - val_acc: 0.8188\n",
      "Epoch 405/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3699 - acc: 0.9878 - val_loss: 0.9217 - val_acc: 0.8774\n",
      "Epoch 406/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3758 - acc: 0.9849 - val_loss: 1.0532 - val_acc: 0.8368\n",
      "Epoch 407/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3692 - acc: 0.9888 - val_loss: 0.8659 - val_acc: 0.8970\n",
      "Epoch 408/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3811 - acc: 0.9862 - val_loss: 1.0169 - val_acc: 0.8609\n",
      "Epoch 409/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3736 - acc: 0.9869 - val_loss: 0.9432 - val_acc: 0.8662\n",
      "Epoch 410/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3693 - acc: 0.9908 - val_loss: 0.8500 - val_acc: 0.8850\n",
      "Epoch 411/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3696 - acc: 0.9902 - val_loss: 0.9027 - val_acc: 0.8707\n",
      "Epoch 412/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3860 - acc: 0.9832 - val_loss: 0.8478 - val_acc: 0.8992\n",
      "Epoch 413/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3678 - acc: 0.9926 - val_loss: 0.8420 - val_acc: 0.9045\n",
      "Epoch 414/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3690 - acc: 0.9932 - val_loss: 0.8321 - val_acc: 0.9053\n",
      "Epoch 415/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3615 - acc: 0.9954 - val_loss: 0.8568 - val_acc: 0.9060\n",
      "Epoch 416/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3656 - acc: 0.9926 - val_loss: 0.8728 - val_acc: 0.8887\n",
      "Epoch 417/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3606 - acc: 0.9936 - val_loss: 0.9189 - val_acc: 0.8729\n",
      "Epoch 418/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3645 - acc: 0.9936 - val_loss: 0.9450 - val_acc: 0.8835\n",
      "Epoch 419/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3675 - acc: 0.9899 - val_loss: 0.9800 - val_acc: 0.8737\n",
      "Epoch 420/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3656 - acc: 0.9945 - val_loss: 0.8606 - val_acc: 0.8925\n",
      "Epoch 421/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3600 - acc: 0.9936 - val_loss: 0.9266 - val_acc: 0.8910\n",
      "Epoch 422/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3578 - acc: 0.9963 - val_loss: 0.8769 - val_acc: 0.8955\n",
      "Epoch 423/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3642 - acc: 0.9926 - val_loss: 1.1664 - val_acc: 0.8316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3544 - acc: 0.9952 - val_loss: 0.8400 - val_acc: 0.8992\n",
      "Epoch 425/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3608 - acc: 0.9908 - val_loss: 0.8700 - val_acc: 0.8850\n",
      "Epoch 426/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3828 - acc: 0.9842 - val_loss: 0.9188 - val_acc: 0.8850\n",
      "Epoch 427/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3734 - acc: 0.9888 - val_loss: 1.4757 - val_acc: 0.7955\n",
      "Epoch 428/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3671 - acc: 0.9897 - val_loss: 0.9275 - val_acc: 0.8782\n",
      "Epoch 429/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3606 - acc: 0.9917 - val_loss: 1.0004 - val_acc: 0.8699\n",
      "Epoch 430/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3526 - acc: 0.9950 - val_loss: 0.8403 - val_acc: 0.8977\n",
      "Epoch 431/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3528 - acc: 0.9963 - val_loss: 1.1265 - val_acc: 0.8496\n",
      "Epoch 432/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3665 - acc: 0.9908 - val_loss: 0.8466 - val_acc: 0.9023\n",
      "Epoch 433/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3553 - acc: 0.9936 - val_loss: 0.8722 - val_acc: 0.9015\n",
      "Epoch 434/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3590 - acc: 0.9926 - val_loss: 0.8518 - val_acc: 0.8962\n",
      "Epoch 435/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3641 - acc: 0.9924 - val_loss: 0.8564 - val_acc: 0.9083\n",
      "Epoch 436/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3519 - acc: 0.9936 - val_loss: 0.8923 - val_acc: 0.8985\n",
      "Epoch 437/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3536 - acc: 0.9952 - val_loss: 0.8874 - val_acc: 0.8940\n",
      "Epoch 438/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3577 - acc: 0.9922 - val_loss: 1.0425 - val_acc: 0.8511\n",
      "Epoch 439/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3539 - acc: 0.9954 - val_loss: 0.9269 - val_acc: 0.8767\n",
      "Epoch 440/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3556 - acc: 0.9959 - val_loss: 1.1348 - val_acc: 0.8414\n",
      "Epoch 441/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3639 - acc: 0.9899 - val_loss: 0.9295 - val_acc: 0.8872\n",
      "Epoch 442/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3635 - acc: 0.9908 - val_loss: 0.8590 - val_acc: 0.8902\n",
      "Epoch 443/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3519 - acc: 0.9954 - val_loss: 0.8508 - val_acc: 0.8955\n",
      "Epoch 444/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3608 - acc: 0.9917 - val_loss: 0.8317 - val_acc: 0.8970\n",
      "Epoch 445/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3622 - acc: 0.9906 - val_loss: 0.8857 - val_acc: 0.8887\n",
      "Epoch 446/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3590 - acc: 0.9917 - val_loss: 0.9667 - val_acc: 0.8617\n",
      "Epoch 447/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3679 - acc: 0.9890 - val_loss: 1.0054 - val_acc: 0.8729\n",
      "Epoch 448/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3587 - acc: 0.9924 - val_loss: 0.8709 - val_acc: 0.8865\n",
      "Epoch 449/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3561 - acc: 0.9926 - val_loss: 1.1048 - val_acc: 0.8368\n",
      "Epoch 450/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3594 - acc: 0.9926 - val_loss: 1.0208 - val_acc: 0.8677\n",
      "Epoch 451/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3499 - acc: 0.9954 - val_loss: 0.8099 - val_acc: 0.9060\n",
      "Epoch 452/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3519 - acc: 0.9934 - val_loss: 0.8388 - val_acc: 0.8940\n",
      "Epoch 453/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3636 - acc: 0.9897 - val_loss: 0.8996 - val_acc: 0.8895\n",
      "Epoch 454/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3550 - acc: 0.9945 - val_loss: 0.8707 - val_acc: 0.8887\n",
      "Epoch 455/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3518 - acc: 0.9943 - val_loss: 0.8371 - val_acc: 0.9015\n",
      "Epoch 456/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3595 - acc: 0.9886 - val_loss: 0.9477 - val_acc: 0.8632\n",
      "Epoch 457/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3610 - acc: 0.9917 - val_loss: 0.9255 - val_acc: 0.8632\n",
      "Epoch 458/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3560 - acc: 0.9904 - val_loss: 0.8892 - val_acc: 0.8902\n",
      "Epoch 459/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3568 - acc: 0.9917 - val_loss: 1.0060 - val_acc: 0.8534\n",
      "Epoch 460/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3515 - acc: 0.9945 - val_loss: 1.0977 - val_acc: 0.8316\n",
      "Epoch 461/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3598 - acc: 0.9890 - val_loss: 1.0517 - val_acc: 0.8444\n",
      "Epoch 462/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3604 - acc: 0.9899 - val_loss: 1.1433 - val_acc: 0.8429\n",
      "Epoch 463/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3634 - acc: 0.9871 - val_loss: 0.8979 - val_acc: 0.9008\n",
      "Epoch 464/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3634 - acc: 0.9890 - val_loss: 0.8554 - val_acc: 0.8962\n",
      "Epoch 465/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3500 - acc: 0.9954 - val_loss: 0.8672 - val_acc: 0.8850\n",
      "Epoch 466/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3487 - acc: 0.9954 - val_loss: 0.8818 - val_acc: 0.8880\n",
      "Epoch 467/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3507 - acc: 0.9952 - val_loss: 1.0431 - val_acc: 0.8556\n",
      "Epoch 468/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3483 - acc: 0.9963 - val_loss: 0.8914 - val_acc: 0.8835\n",
      "Epoch 469/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3566 - acc: 0.9917 - val_loss: 1.0263 - val_acc: 0.8466\n",
      "Epoch 470/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3514 - acc: 0.9934 - val_loss: 0.9231 - val_acc: 0.8782\n",
      "Epoch 471/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3479 - acc: 0.9952 - val_loss: 0.8726 - val_acc: 0.8992\n",
      "Epoch 472/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3485 - acc: 0.9952 - val_loss: 0.8872 - val_acc: 0.8962\n",
      "Epoch 473/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3507 - acc: 0.9936 - val_loss: 0.9596 - val_acc: 0.8752\n",
      "Epoch 474/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3431 - acc: 0.9954 - val_loss: 0.9734 - val_acc: 0.8752\n",
      "Epoch 475/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3482 - acc: 0.9936 - val_loss: 0.9294 - val_acc: 0.8669\n",
      "Epoch 476/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3538 - acc: 0.9943 - val_loss: 0.8300 - val_acc: 0.9075\n",
      "Epoch 477/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3489 - acc: 0.9924 - val_loss: 0.9085 - val_acc: 0.8902\n",
      "Epoch 478/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3482 - acc: 0.9963 - val_loss: 0.9234 - val_acc: 0.8872\n",
      "Epoch 479/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3505 - acc: 0.9908 - val_loss: 0.8790 - val_acc: 0.8902\n",
      "Epoch 480/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3555 - acc: 0.9920 - val_loss: 0.9061 - val_acc: 0.8782\n",
      "Epoch 481/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3437 - acc: 0.9982 - val_loss: 0.9322 - val_acc: 0.8669\n",
      "Epoch 482/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3494 - acc: 0.9943 - val_loss: 0.8461 - val_acc: 0.9015\n",
      "Epoch 483/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3437 - acc: 0.9970 - val_loss: 0.8446 - val_acc: 0.8977\n",
      "Epoch 484/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3634 - acc: 0.9906 - val_loss: 0.8681 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3400 - acc: 0.9982 - val_loss: 0.8539 - val_acc: 0.9008\n",
      "Epoch 486/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3460 - acc: 0.9972 - val_loss: 0.8581 - val_acc: 0.9000\n",
      "Epoch 487/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3483 - acc: 0.9917 - val_loss: 0.9794 - val_acc: 0.8737\n",
      "Epoch 488/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3416 - acc: 0.9954 - val_loss: 0.8730 - val_acc: 0.8962\n",
      "Epoch 489/1000\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.3510 - acc: 0.9936 - val_loss: 0.8722 - val_acc: 0.8947\n",
      "Epoch 490/1000\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 0.3481 - acc: 0.9908 - val_loss: 0.9767 - val_acc: 0.8534\n",
      "Epoch 491/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3509 - acc: 0.9926 - val_loss: 0.8514 - val_acc: 0.8902\n",
      "Epoch 492/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3557 - acc: 0.9897 - val_loss: 0.8693 - val_acc: 0.8917\n",
      "Epoch 493/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3508 - acc: 0.9917 - val_loss: 1.0393 - val_acc: 0.8474\n",
      "Epoch 494/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3567 - acc: 0.9908 - val_loss: 0.8405 - val_acc: 0.9075\n",
      "Epoch 495/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3505 - acc: 0.9906 - val_loss: 1.3778 - val_acc: 0.8090\n",
      "Epoch 496/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3428 - acc: 0.9972 - val_loss: 1.1551 - val_acc: 0.8436\n",
      "Epoch 497/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.3509 - acc: 0.9890 - val_loss: 1.0150 - val_acc: 0.8744\n",
      "Epoch 498/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3444 - acc: 0.9932 - val_loss: 1.0131 - val_acc: 0.8744\n",
      "Epoch 499/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3530 - acc: 0.9884 - val_loss: 1.2338 - val_acc: 0.8346\n",
      "Epoch 500/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.3650 - acc: 0.9874 - val_loss: 0.8580 - val_acc: 0.8992\n",
      "Epoch 501/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.3505 - acc: 0.9906 - val_loss: 0.9024 - val_acc: 0.8887\n",
      "Epoch 502/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3425 - acc: 0.9945 - val_loss: 0.9576 - val_acc: 0.8850\n",
      "Epoch 503/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3541 - acc: 0.9945 - val_loss: 0.9579 - val_acc: 0.8654\n",
      "Epoch 504/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3417 - acc: 0.9963 - val_loss: 0.9132 - val_acc: 0.8797\n",
      "Epoch 505/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3533 - acc: 0.9899 - val_loss: 0.9078 - val_acc: 0.8895\n",
      "Epoch 506/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3553 - acc: 0.9880 - val_loss: 0.9406 - val_acc: 0.8880\n",
      "Epoch 507/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3454 - acc: 0.9943 - val_loss: 0.8479 - val_acc: 0.8985\n",
      "Epoch 508/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3422 - acc: 0.9954 - val_loss: 0.8437 - val_acc: 0.9083\n",
      "Epoch 509/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3397 - acc: 0.9963 - val_loss: 1.1514 - val_acc: 0.8496\n",
      "Epoch 510/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3341 - acc: 0.9982 - val_loss: 0.8722 - val_acc: 0.9023\n",
      "Epoch 511/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3418 - acc: 0.9972 - val_loss: 0.8399 - val_acc: 0.9038\n",
      "Epoch 512/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3468 - acc: 0.9934 - val_loss: 0.8247 - val_acc: 0.9075\n",
      "Epoch 513/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3387 - acc: 0.9961 - val_loss: 0.7997 - val_acc: 0.9060\n",
      "Epoch 514/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3459 - acc: 0.9915 - val_loss: 0.8486 - val_acc: 0.8940\n",
      "Epoch 515/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3421 - acc: 0.9945 - val_loss: 0.8669 - val_acc: 0.8917\n",
      "Epoch 516/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3431 - acc: 0.9963 - val_loss: 0.8787 - val_acc: 0.8932\n",
      "Epoch 517/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3442 - acc: 0.9941 - val_loss: 0.9875 - val_acc: 0.8759\n",
      "Epoch 518/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3440 - acc: 0.9941 - val_loss: 0.8886 - val_acc: 0.8895\n",
      "Epoch 519/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3369 - acc: 0.9961 - val_loss: 0.8484 - val_acc: 0.9008\n",
      "Epoch 520/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3424 - acc: 0.9952 - val_loss: 0.8498 - val_acc: 0.8985\n",
      "Epoch 521/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3412 - acc: 0.9952 - val_loss: 0.8677 - val_acc: 0.8910\n",
      "Epoch 522/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3369 - acc: 0.9972 - val_loss: 0.8605 - val_acc: 0.8835\n",
      "Epoch 523/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3416 - acc: 0.9899 - val_loss: 0.8324 - val_acc: 0.9000\n",
      "Epoch 524/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3380 - acc: 0.9952 - val_loss: 0.9142 - val_acc: 0.8714\n",
      "Epoch 525/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3420 - acc: 0.9954 - val_loss: 1.0505 - val_acc: 0.8429\n",
      "Epoch 526/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3460 - acc: 0.9934 - val_loss: 0.8375 - val_acc: 0.8977\n",
      "Epoch 527/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3505 - acc: 0.9926 - val_loss: 0.9223 - val_acc: 0.8707\n",
      "Epoch 528/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3457 - acc: 0.9915 - val_loss: 0.8515 - val_acc: 0.8977\n",
      "Epoch 529/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3512 - acc: 0.9876 - val_loss: 0.9124 - val_acc: 0.8850\n",
      "Epoch 530/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3403 - acc: 0.9954 - val_loss: 1.1069 - val_acc: 0.8406\n",
      "Epoch 531/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3398 - acc: 0.9963 - val_loss: 0.9120 - val_acc: 0.8865\n",
      "Epoch 532/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3359 - acc: 0.9972 - val_loss: 0.8167 - val_acc: 0.9008\n",
      "Epoch 533/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3375 - acc: 0.9954 - val_loss: 0.9480 - val_acc: 0.8805\n",
      "Epoch 534/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3419 - acc: 0.9936 - val_loss: 1.3742 - val_acc: 0.8218\n",
      "Epoch 535/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.3368 - acc: 0.9954 - val_loss: 0.9544 - val_acc: 0.8887\n",
      "Epoch 536/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3392 - acc: 0.9943 - val_loss: 0.8522 - val_acc: 0.8977\n",
      "Epoch 537/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3435 - acc: 0.9963 - val_loss: 1.5250 - val_acc: 0.8008\n",
      "Epoch 538/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3424 - acc: 0.9945 - val_loss: 1.1727 - val_acc: 0.8398\n",
      "Epoch 539/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3380 - acc: 0.9963 - val_loss: 0.8431 - val_acc: 0.8970\n",
      "Epoch 540/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3461 - acc: 0.9934 - val_loss: 0.8658 - val_acc: 0.8970\n",
      "Epoch 541/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3492 - acc: 0.9899 - val_loss: 0.9942 - val_acc: 0.8759\n",
      "Epoch 542/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3409 - acc: 0.9950 - val_loss: 0.9242 - val_acc: 0.8692\n",
      "Epoch 543/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3439 - acc: 0.9936 - val_loss: 0.8694 - val_acc: 0.8925\n",
      "Epoch 544/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3666 - acc: 0.9838 - val_loss: 0.8598 - val_acc: 0.9075\n",
      "Epoch 545/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3395 - acc: 0.9926 - val_loss: 0.8413 - val_acc: 0.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3396 - acc: 0.9936 - val_loss: 0.9707 - val_acc: 0.8714\n",
      "Epoch 547/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3375 - acc: 0.9963 - val_loss: 0.8062 - val_acc: 0.9060\n",
      "Epoch 548/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3318 - acc: 0.9954 - val_loss: 0.9901 - val_acc: 0.8699\n",
      "Epoch 549/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3299 - acc: 0.9982 - val_loss: 0.9673 - val_acc: 0.8714\n",
      "Epoch 550/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3373 - acc: 0.9915 - val_loss: 0.8262 - val_acc: 0.9105\n",
      "Epoch 551/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3375 - acc: 0.9936 - val_loss: 0.8530 - val_acc: 0.8835\n",
      "Epoch 552/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3407 - acc: 0.9932 - val_loss: 1.0444 - val_acc: 0.8398\n",
      "Epoch 553/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3331 - acc: 0.9963 - val_loss: 0.8345 - val_acc: 0.9053\n",
      "Epoch 554/1000\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 0.3366 - acc: 0.9943 - val_loss: 0.8238 - val_acc: 0.9083\n",
      "Epoch 555/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3324 - acc: 0.9945 - val_loss: 0.9232 - val_acc: 0.8692\n",
      "Epoch 556/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3406 - acc: 0.9943 - val_loss: 0.8039 - val_acc: 0.9060\n",
      "Epoch 557/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3329 - acc: 0.9963 - val_loss: 0.8300 - val_acc: 0.9068\n",
      "Epoch 558/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3328 - acc: 0.9950 - val_loss: 0.8574 - val_acc: 0.9015\n",
      "Epoch 559/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3396 - acc: 0.9936 - val_loss: 0.9102 - val_acc: 0.8774\n",
      "Epoch 560/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3396 - acc: 0.9936 - val_loss: 0.8499 - val_acc: 0.8992\n",
      "Epoch 561/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3369 - acc: 0.9945 - val_loss: 0.8650 - val_acc: 0.9023\n",
      "Epoch 562/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3407 - acc: 0.9932 - val_loss: 0.8725 - val_acc: 0.8985\n",
      "Epoch 563/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3369 - acc: 0.9954 - val_loss: 0.9188 - val_acc: 0.8842\n",
      "Epoch 564/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3350 - acc: 0.9954 - val_loss: 0.8722 - val_acc: 0.8932\n",
      "Epoch 565/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3413 - acc: 0.9917 - val_loss: 1.0534 - val_acc: 0.8444\n",
      "Epoch 566/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3459 - acc: 0.9867 - val_loss: 0.8741 - val_acc: 0.8895\n",
      "Epoch 567/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3392 - acc: 0.9924 - val_loss: 0.9362 - val_acc: 0.8594\n",
      "Epoch 568/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3358 - acc: 0.9936 - val_loss: 0.8735 - val_acc: 0.8737\n",
      "Epoch 569/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3364 - acc: 0.9920 - val_loss: 1.0523 - val_acc: 0.8383\n",
      "Epoch 570/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3379 - acc: 0.9963 - val_loss: 0.9470 - val_acc: 0.8759\n",
      "Epoch 571/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3336 - acc: 0.9954 - val_loss: 0.8273 - val_acc: 0.9000\n",
      "Epoch 572/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3407 - acc: 0.9936 - val_loss: 0.8613 - val_acc: 0.8947\n",
      "Epoch 573/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3369 - acc: 0.9934 - val_loss: 1.0570 - val_acc: 0.8586\n",
      "Epoch 574/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3304 - acc: 0.9970 - val_loss: 1.5653 - val_acc: 0.7985\n",
      "Epoch 575/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3332 - acc: 0.9943 - val_loss: 0.8065 - val_acc: 0.9068\n",
      "Epoch 576/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.3320 - acc: 0.9954 - val_loss: 0.8341 - val_acc: 0.9030\n",
      "Epoch 577/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3296 - acc: 0.9963 - val_loss: 0.8351 - val_acc: 0.9045\n",
      "Epoch 578/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3433 - acc: 0.9897 - val_loss: 0.9968 - val_acc: 0.8609\n",
      "Epoch 579/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3326 - acc: 0.9954 - val_loss: 0.8575 - val_acc: 0.8910\n",
      "Epoch 580/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3322 - acc: 0.9945 - val_loss: 0.8317 - val_acc: 0.8992\n",
      "Epoch 581/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3285 - acc: 0.9952 - val_loss: 0.9369 - val_acc: 0.8692\n",
      "Epoch 582/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3251 - acc: 0.9982 - val_loss: 0.9191 - val_acc: 0.8812\n",
      "Epoch 583/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3299 - acc: 0.9963 - val_loss: 0.9074 - val_acc: 0.8812\n",
      "Epoch 584/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3243 - acc: 0.9954 - val_loss: 0.8356 - val_acc: 0.8940\n",
      "Epoch 585/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3356 - acc: 0.9926 - val_loss: 0.8819 - val_acc: 0.8962\n",
      "Epoch 586/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3325 - acc: 0.9959 - val_loss: 0.9887 - val_acc: 0.8699\n",
      "Epoch 587/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3284 - acc: 0.9943 - val_loss: 0.9017 - val_acc: 0.8917\n",
      "Epoch 588/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3290 - acc: 0.9972 - val_loss: 0.9098 - val_acc: 0.8887\n",
      "Epoch 589/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3283 - acc: 0.9963 - val_loss: 0.8852 - val_acc: 0.8962\n",
      "Epoch 590/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3280 - acc: 0.9954 - val_loss: 0.8235 - val_acc: 0.9045\n",
      "Epoch 591/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3273 - acc: 0.9972 - val_loss: 0.8151 - val_acc: 0.9113\n",
      "Epoch 592/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3325 - acc: 0.9945 - val_loss: 0.8566 - val_acc: 0.8947\n",
      "Epoch 593/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3325 - acc: 0.9954 - val_loss: 0.8480 - val_acc: 0.9008\n",
      "Epoch 594/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3308 - acc: 0.9945 - val_loss: 0.8125 - val_acc: 0.9030\n",
      "Epoch 595/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3312 - acc: 0.9945 - val_loss: 0.9588 - val_acc: 0.8654\n",
      "Epoch 596/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3263 - acc: 0.9982 - val_loss: 0.8362 - val_acc: 0.9068\n",
      "Epoch 597/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3256 - acc: 0.9952 - val_loss: 0.8515 - val_acc: 0.8872\n",
      "Epoch 598/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3305 - acc: 0.9945 - val_loss: 0.8411 - val_acc: 0.9083\n",
      "Epoch 599/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3279 - acc: 0.9963 - val_loss: 0.9892 - val_acc: 0.8752\n",
      "Epoch 600/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3325 - acc: 0.9950 - val_loss: 0.8667 - val_acc: 0.8925\n",
      "Epoch 601/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3275 - acc: 0.9963 - val_loss: 0.8656 - val_acc: 0.8880\n",
      "Epoch 602/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3291 - acc: 0.9982 - val_loss: 0.8974 - val_acc: 0.8835\n",
      "Epoch 603/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3289 - acc: 0.9972 - val_loss: 1.1403 - val_acc: 0.8429\n",
      "Epoch 604/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3290 - acc: 0.9936 - val_loss: 0.9430 - val_acc: 0.8774\n",
      "Epoch 605/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3214 - acc: 0.9982 - val_loss: 0.9281 - val_acc: 0.8820\n",
      "Epoch 606/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3283 - acc: 0.9941 - val_loss: 0.8819 - val_acc: 0.8865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3343 - acc: 0.9926 - val_loss: 1.0231 - val_acc: 0.8692\n",
      "Epoch 608/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3438 - acc: 0.9867 - val_loss: 0.9434 - val_acc: 0.8707\n",
      "Epoch 609/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3258 - acc: 0.9954 - val_loss: 0.8705 - val_acc: 0.8880\n",
      "Epoch 610/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3275 - acc: 0.9963 - val_loss: 0.8555 - val_acc: 0.8902\n",
      "Epoch 611/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3207 - acc: 0.9991 - val_loss: 0.8507 - val_acc: 0.8985\n",
      "Epoch 612/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3231 - acc: 0.9982 - val_loss: 0.8147 - val_acc: 0.9135\n",
      "Epoch 613/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3265 - acc: 0.9982 - val_loss: 0.7904 - val_acc: 0.9135\n",
      "Epoch 614/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3218 - acc: 0.9982 - val_loss: 0.8396 - val_acc: 0.8947\n",
      "Epoch 615/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3310 - acc: 0.9945 - val_loss: 0.8541 - val_acc: 0.8902\n",
      "Epoch 616/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3318 - acc: 0.9924 - val_loss: 0.8066 - val_acc: 0.9113\n",
      "Epoch 617/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3298 - acc: 0.9934 - val_loss: 0.8108 - val_acc: 0.9143\n",
      "Epoch 618/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3287 - acc: 0.9917 - val_loss: 0.8244 - val_acc: 0.9113\n",
      "Epoch 619/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3253 - acc: 0.9943 - val_loss: 0.8721 - val_acc: 0.9030\n",
      "Epoch 620/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3260 - acc: 0.9954 - val_loss: 1.0967 - val_acc: 0.8549\n",
      "Epoch 621/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3356 - acc: 0.9920 - val_loss: 2.9274 - val_acc: 0.6827\n",
      "Epoch 622/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3298 - acc: 0.9943 - val_loss: 1.8159 - val_acc: 0.7782\n",
      "Epoch 623/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3245 - acc: 0.9936 - val_loss: 0.9731 - val_acc: 0.8714\n",
      "Epoch 624/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3273 - acc: 0.9945 - val_loss: 0.8835 - val_acc: 0.8947\n",
      "Epoch 625/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3243 - acc: 0.9950 - val_loss: 1.2178 - val_acc: 0.8301\n",
      "Epoch 626/1000\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 0.3241 - acc: 0.9952 - val_loss: 0.8339 - val_acc: 0.9098\n",
      "Epoch 627/1000\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.3221 - acc: 0.9963 - val_loss: 0.9579 - val_acc: 0.8782\n",
      "Epoch 628/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3170 - acc: 0.9982 - val_loss: 0.8612 - val_acc: 0.9068\n",
      "Epoch 629/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3233 - acc: 0.9963 - val_loss: 0.8721 - val_acc: 0.8917\n",
      "Epoch 630/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3226 - acc: 0.9961 - val_loss: 0.8372 - val_acc: 0.9015\n",
      "Epoch 631/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3222 - acc: 0.9945 - val_loss: 0.8376 - val_acc: 0.9038\n",
      "Epoch 632/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3254 - acc: 0.9954 - val_loss: 0.8339 - val_acc: 0.9090\n",
      "Epoch 633/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3192 - acc: 0.9982 - val_loss: 0.8227 - val_acc: 0.9030\n",
      "Epoch 634/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3261 - acc: 0.9963 - val_loss: 0.9837 - val_acc: 0.8556\n",
      "Epoch 635/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3357 - acc: 0.9913 - val_loss: 1.0027 - val_acc: 0.8624\n",
      "Epoch 636/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3279 - acc: 0.9943 - val_loss: 1.2124 - val_acc: 0.8293\n",
      "Epoch 637/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3221 - acc: 0.9945 - val_loss: 0.8427 - val_acc: 0.8932\n",
      "Epoch 638/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3232 - acc: 0.9961 - val_loss: 0.8129 - val_acc: 0.9000\n",
      "Epoch 639/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3191 - acc: 0.9972 - val_loss: 0.9716 - val_acc: 0.8677\n",
      "Epoch 640/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3203 - acc: 0.9963 - val_loss: 0.8385 - val_acc: 0.9038\n",
      "Epoch 641/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3235 - acc: 0.9954 - val_loss: 0.8460 - val_acc: 0.8962\n",
      "Epoch 642/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3249 - acc: 0.9954 - val_loss: 0.8685 - val_acc: 0.8820\n",
      "Epoch 643/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3234 - acc: 0.9943 - val_loss: 0.8241 - val_acc: 0.8895\n",
      "Epoch 644/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3198 - acc: 0.9963 - val_loss: 0.8055 - val_acc: 0.8932\n",
      "Epoch 645/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3162 - acc: 0.9980 - val_loss: 0.7734 - val_acc: 0.9105\n",
      "Epoch 646/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3250 - acc: 0.9945 - val_loss: 0.8398 - val_acc: 0.9008\n",
      "Epoch 647/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3207 - acc: 0.9954 - val_loss: 0.8604 - val_acc: 0.8962\n",
      "Epoch 648/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3214 - acc: 0.9945 - val_loss: 0.9002 - val_acc: 0.8850\n",
      "Epoch 649/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3235 - acc: 0.9936 - val_loss: 0.8456 - val_acc: 0.9000\n",
      "Epoch 650/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3237 - acc: 0.9954 - val_loss: 0.9207 - val_acc: 0.8797\n",
      "Epoch 651/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3179 - acc: 0.9982 - val_loss: 1.0930 - val_acc: 0.8549\n",
      "Epoch 652/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3204 - acc: 0.9963 - val_loss: 0.7938 - val_acc: 0.9060\n",
      "Epoch 653/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3258 - acc: 0.9904 - val_loss: 0.8114 - val_acc: 0.9060\n",
      "Epoch 654/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3200 - acc: 0.9972 - val_loss: 1.1091 - val_acc: 0.8534\n",
      "Epoch 655/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3175 - acc: 0.9982 - val_loss: 0.9532 - val_acc: 0.8789\n",
      "Epoch 656/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3224 - acc: 0.9945 - val_loss: 0.8232 - val_acc: 0.9030\n",
      "Epoch 657/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3158 - acc: 0.9972 - val_loss: 0.8199 - val_acc: 0.9135\n",
      "Epoch 658/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3143 - acc: 0.9991 - val_loss: 0.7938 - val_acc: 0.9105\n",
      "Epoch 659/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3144 - acc: 0.9961 - val_loss: 0.7803 - val_acc: 0.9113\n",
      "Epoch 660/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3224 - acc: 0.9954 - val_loss: 0.8076 - val_acc: 0.9068\n",
      "Epoch 661/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3219 - acc: 0.9936 - val_loss: 0.8566 - val_acc: 0.8962\n",
      "Epoch 662/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3243 - acc: 0.9954 - val_loss: 1.0051 - val_acc: 0.8586\n",
      "Epoch 663/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3236 - acc: 0.9945 - val_loss: 0.8321 - val_acc: 0.9015\n",
      "Epoch 664/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3169 - acc: 0.9972 - val_loss: 0.9181 - val_acc: 0.8729\n",
      "Epoch 665/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3164 - acc: 0.9963 - val_loss: 0.8180 - val_acc: 0.9083\n",
      "Epoch 666/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3181 - acc: 0.9954 - val_loss: 0.8005 - val_acc: 0.9023\n",
      "Epoch 667/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3160 - acc: 0.9982 - val_loss: 0.8347 - val_acc: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3125 - acc: 0.9982 - val_loss: 1.1199 - val_acc: 0.8383\n",
      "Epoch 669/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3125 - acc: 0.9972 - val_loss: 1.0583 - val_acc: 0.8429\n",
      "Epoch 670/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3128 - acc: 0.9972 - val_loss: 1.0195 - val_acc: 0.8549\n",
      "Epoch 671/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3136 - acc: 0.9972 - val_loss: 0.8466 - val_acc: 0.8917\n",
      "Epoch 672/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3117 - acc: 0.9954 - val_loss: 0.8244 - val_acc: 0.9030\n",
      "Epoch 673/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3179 - acc: 0.9945 - val_loss: 0.8484 - val_acc: 0.8917\n",
      "Epoch 674/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3156 - acc: 0.9982 - val_loss: 1.1195 - val_acc: 0.8353\n",
      "Epoch 675/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3142 - acc: 0.9982 - val_loss: 0.8584 - val_acc: 0.8925\n",
      "Epoch 676/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3145 - acc: 0.9961 - val_loss: 0.7721 - val_acc: 0.9158\n",
      "Epoch 677/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3127 - acc: 0.9963 - val_loss: 0.8045 - val_acc: 0.9038\n",
      "Epoch 678/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3071 - acc: 1.0000 - val_loss: 0.7750 - val_acc: 0.9218\n",
      "Epoch 679/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3138 - acc: 0.9972 - val_loss: 0.7540 - val_acc: 0.9233\n",
      "Epoch 680/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3127 - acc: 0.9980 - val_loss: 0.8336 - val_acc: 0.8970\n",
      "Epoch 681/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3184 - acc: 0.9945 - val_loss: 0.9071 - val_acc: 0.8925\n",
      "Epoch 682/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3129 - acc: 0.9954 - val_loss: 1.0185 - val_acc: 0.8707\n",
      "Epoch 683/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3216 - acc: 0.9945 - val_loss: 1.0388 - val_acc: 0.8481\n",
      "Epoch 684/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3192 - acc: 0.9932 - val_loss: 0.8233 - val_acc: 0.8985\n",
      "Epoch 685/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3189 - acc: 0.9954 - val_loss: 0.8399 - val_acc: 0.8917\n",
      "Epoch 686/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3296 - acc: 0.9899 - val_loss: 0.8333 - val_acc: 0.8992\n",
      "Epoch 687/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3290 - acc: 0.9908 - val_loss: 0.9650 - val_acc: 0.8729\n",
      "Epoch 688/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3228 - acc: 0.9945 - val_loss: 1.1206 - val_acc: 0.8414\n",
      "Epoch 689/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3146 - acc: 0.9972 - val_loss: 0.9904 - val_acc: 0.8677\n",
      "Epoch 690/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3170 - acc: 0.9943 - val_loss: 0.8985 - val_acc: 0.8805\n",
      "Epoch 691/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3186 - acc: 0.9934 - val_loss: 0.8108 - val_acc: 0.9075\n",
      "Epoch 692/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3082 - acc: 0.9982 - val_loss: 0.9161 - val_acc: 0.8850\n",
      "Epoch 693/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3255 - acc: 0.9926 - val_loss: 1.0051 - val_acc: 0.8759\n",
      "Epoch 694/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3180 - acc: 0.9970 - val_loss: 0.8307 - val_acc: 0.9090\n",
      "Epoch 695/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3083 - acc: 0.9972 - val_loss: 0.8853 - val_acc: 0.8947\n",
      "Epoch 696/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3200 - acc: 0.9934 - val_loss: 0.7776 - val_acc: 0.9128\n",
      "Epoch 697/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3164 - acc: 0.9961 - val_loss: 0.9540 - val_acc: 0.8707\n",
      "Epoch 698/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3095 - acc: 0.9961 - val_loss: 0.8524 - val_acc: 0.9008\n",
      "Epoch 699/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3141 - acc: 0.9954 - val_loss: 1.3649 - val_acc: 0.8180\n",
      "Epoch 700/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3086 - acc: 0.9991 - val_loss: 1.5402 - val_acc: 0.8113\n",
      "Epoch 701/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3227 - acc: 0.9917 - val_loss: 0.9063 - val_acc: 0.8797\n",
      "Epoch 702/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3259 - acc: 0.9936 - val_loss: 1.1276 - val_acc: 0.8571\n",
      "Epoch 703/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3306 - acc: 0.9899 - val_loss: 1.4535 - val_acc: 0.8045\n",
      "Epoch 704/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3163 - acc: 0.9952 - val_loss: 1.5547 - val_acc: 0.7827\n",
      "Epoch 705/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3150 - acc: 0.9952 - val_loss: 0.8962 - val_acc: 0.8925\n",
      "Epoch 706/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3111 - acc: 0.9963 - val_loss: 0.9931 - val_acc: 0.8579\n",
      "Epoch 707/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3189 - acc: 0.9945 - val_loss: 1.1663 - val_acc: 0.8376\n",
      "Epoch 708/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3164 - acc: 0.9945 - val_loss: 1.0081 - val_acc: 0.8684\n",
      "Epoch 709/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3242 - acc: 0.9934 - val_loss: 0.8393 - val_acc: 0.9008\n",
      "Epoch 710/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3179 - acc: 0.9954 - val_loss: 0.8413 - val_acc: 0.9030\n",
      "Epoch 711/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3154 - acc: 0.9963 - val_loss: 1.2110 - val_acc: 0.8398\n",
      "Epoch 712/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3128 - acc: 0.9945 - val_loss: 1.1183 - val_acc: 0.8579\n",
      "Epoch 713/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3056 - acc: 0.9982 - val_loss: 0.7838 - val_acc: 0.9165\n",
      "Epoch 714/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3110 - acc: 0.9972 - val_loss: 0.8208 - val_acc: 0.8977\n",
      "Epoch 715/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3100 - acc: 0.9972 - val_loss: 0.7772 - val_acc: 0.9158\n",
      "Epoch 716/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3176 - acc: 0.9908 - val_loss: 0.7903 - val_acc: 0.9173\n",
      "Epoch 717/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3056 - acc: 0.9982 - val_loss: 0.8105 - val_acc: 0.9120\n",
      "Epoch 718/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3183 - acc: 0.9926 - val_loss: 0.9099 - val_acc: 0.8767\n",
      "Epoch 719/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3136 - acc: 0.9954 - val_loss: 1.0312 - val_acc: 0.8474\n",
      "Epoch 720/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3073 - acc: 0.9991 - val_loss: 0.9449 - val_acc: 0.8677\n",
      "Epoch 721/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3089 - acc: 0.9963 - val_loss: 0.9172 - val_acc: 0.8820\n",
      "Epoch 722/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3101 - acc: 0.9972 - val_loss: 1.3079 - val_acc: 0.8143\n",
      "Epoch 723/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3062 - acc: 0.9982 - val_loss: 0.9387 - val_acc: 0.8797\n",
      "Epoch 724/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3110 - acc: 0.9945 - val_loss: 0.9198 - val_acc: 0.8782\n",
      "Epoch 725/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3157 - acc: 0.9952 - val_loss: 0.9135 - val_acc: 0.8797\n",
      "Epoch 726/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3115 - acc: 0.9945 - val_loss: 0.9602 - val_acc: 0.8617\n",
      "Epoch 727/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3146 - acc: 0.9961 - val_loss: 0.8744 - val_acc: 0.8902\n",
      "Epoch 728/1000\n",
      "17/17 [==============================] - 1s 81ms/step - loss: 0.3241 - acc: 0.9908 - val_loss: 0.8933 - val_acc: 0.8835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3222 - acc: 0.9906 - val_loss: 0.9776 - val_acc: 0.8669\n",
      "Epoch 730/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3123 - acc: 0.9908 - val_loss: 1.0449 - val_acc: 0.8534\n",
      "Epoch 731/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3149 - acc: 0.9936 - val_loss: 0.9567 - val_acc: 0.8654\n",
      "Epoch 732/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3106 - acc: 0.9954 - val_loss: 0.8794 - val_acc: 0.8789\n",
      "Epoch 733/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3102 - acc: 0.9963 - val_loss: 0.8477 - val_acc: 0.8970\n",
      "Epoch 734/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3102 - acc: 0.9945 - val_loss: 0.8244 - val_acc: 0.9030\n",
      "Epoch 735/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3100 - acc: 0.9943 - val_loss: 0.7724 - val_acc: 0.9143\n",
      "Epoch 736/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3065 - acc: 0.9954 - val_loss: 0.8238 - val_acc: 0.8880\n",
      "Epoch 737/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3092 - acc: 0.9963 - val_loss: 0.8103 - val_acc: 0.8940\n",
      "Epoch 738/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.3074 - acc: 0.9963 - val_loss: 0.7865 - val_acc: 0.9165\n",
      "Epoch 739/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3111 - acc: 0.9954 - val_loss: 0.7936 - val_acc: 0.9203\n",
      "Epoch 740/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3070 - acc: 0.9945 - val_loss: 0.7947 - val_acc: 0.9218\n",
      "Epoch 741/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3118 - acc: 0.9934 - val_loss: 0.8772 - val_acc: 0.8835\n",
      "Epoch 742/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3076 - acc: 0.9954 - val_loss: 0.7765 - val_acc: 0.9068\n",
      "Epoch 743/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3035 - acc: 0.9972 - val_loss: 0.7479 - val_acc: 0.9150\n",
      "Epoch 744/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3006 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.9128\n",
      "Epoch 745/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3014 - acc: 0.9991 - val_loss: 0.7630 - val_acc: 0.9203\n",
      "Epoch 746/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3031 - acc: 0.9978 - val_loss: 0.9733 - val_acc: 0.8797\n",
      "Epoch 747/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3009 - acc: 0.9991 - val_loss: 0.8032 - val_acc: 0.9143\n",
      "Epoch 748/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3053 - acc: 0.9954 - val_loss: 0.7756 - val_acc: 0.9158\n",
      "Epoch 749/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2995 - acc: 0.9991 - val_loss: 0.7789 - val_acc: 0.9188\n",
      "Epoch 750/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3041 - acc: 0.9963 - val_loss: 0.8377 - val_acc: 0.9098\n",
      "Epoch 751/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3083 - acc: 0.9945 - val_loss: 0.9285 - val_acc: 0.8812\n",
      "Epoch 752/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3050 - acc: 0.9970 - val_loss: 0.9458 - val_acc: 0.8729\n",
      "Epoch 753/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3030 - acc: 0.9982 - val_loss: 0.9533 - val_acc: 0.8812\n",
      "Epoch 754/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3085 - acc: 0.9936 - val_loss: 0.8128 - val_acc: 0.9150\n",
      "Epoch 755/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.3073 - acc: 0.9945 - val_loss: 0.8464 - val_acc: 0.9068\n",
      "Epoch 756/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3088 - acc: 0.9952 - val_loss: 0.9316 - val_acc: 0.8865\n",
      "Epoch 757/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3054 - acc: 0.9954 - val_loss: 0.9035 - val_acc: 0.8805\n",
      "Epoch 758/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3004 - acc: 0.9972 - val_loss: 0.8052 - val_acc: 0.9045\n",
      "Epoch 759/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3015 - acc: 0.9972 - val_loss: 0.8174 - val_acc: 0.9023\n",
      "Epoch 760/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3017 - acc: 0.9963 - val_loss: 0.8444 - val_acc: 0.9015\n",
      "Epoch 761/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3016 - acc: 0.9963 - val_loss: 0.8898 - val_acc: 0.8827\n",
      "Epoch 762/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2959 - acc: 1.0000 - val_loss: 0.8179 - val_acc: 0.9000\n",
      "Epoch 763/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3030 - acc: 0.9970 - val_loss: 0.8073 - val_acc: 0.9030\n",
      "Epoch 764/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3062 - acc: 0.9943 - val_loss: 0.7758 - val_acc: 0.9195\n",
      "Epoch 765/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3003 - acc: 0.9991 - val_loss: 1.1031 - val_acc: 0.8571\n",
      "Epoch 766/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3026 - acc: 0.9945 - val_loss: 0.7952 - val_acc: 0.9113\n",
      "Epoch 767/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2992 - acc: 0.9970 - val_loss: 1.1031 - val_acc: 0.8406\n",
      "Epoch 768/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3040 - acc: 0.9945 - val_loss: 1.3024 - val_acc: 0.8180\n",
      "Epoch 769/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3107 - acc: 0.9913 - val_loss: 0.8496 - val_acc: 0.8865\n",
      "Epoch 770/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3088 - acc: 0.9936 - val_loss: 0.9031 - val_acc: 0.8729\n",
      "Epoch 771/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3119 - acc: 0.9926 - val_loss: 0.8006 - val_acc: 0.9038\n",
      "Epoch 772/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3042 - acc: 0.9963 - val_loss: 0.9107 - val_acc: 0.8827\n",
      "Epoch 773/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3056 - acc: 0.9934 - val_loss: 1.3216 - val_acc: 0.8233\n",
      "Epoch 774/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2988 - acc: 0.9982 - val_loss: 0.8151 - val_acc: 0.9075\n",
      "Epoch 775/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3000 - acc: 0.9963 - val_loss: 0.8028 - val_acc: 0.9098\n",
      "Epoch 776/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2969 - acc: 0.9991 - val_loss: 0.8194 - val_acc: 0.8992\n",
      "Epoch 777/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3028 - acc: 0.9959 - val_loss: 0.9393 - val_acc: 0.8887\n",
      "Epoch 778/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3062 - acc: 0.9982 - val_loss: 0.8402 - val_acc: 0.9060\n",
      "Epoch 779/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2989 - acc: 0.9980 - val_loss: 0.7714 - val_acc: 0.9083\n",
      "Epoch 780/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2964 - acc: 0.9991 - val_loss: 0.7762 - val_acc: 0.9135\n",
      "Epoch 781/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2992 - acc: 0.9961 - val_loss: 0.7926 - val_acc: 0.9068\n",
      "Epoch 782/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2984 - acc: 0.9982 - val_loss: 0.7894 - val_acc: 0.9135\n",
      "Epoch 783/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2987 - acc: 0.9963 - val_loss: 0.8015 - val_acc: 0.9113\n",
      "Epoch 784/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2983 - acc: 0.9982 - val_loss: 0.8407 - val_acc: 0.9030\n",
      "Epoch 785/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.3013 - acc: 0.9963 - val_loss: 0.8099 - val_acc: 0.9105\n",
      "Epoch 786/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3011 - acc: 0.9972 - val_loss: 0.9869 - val_acc: 0.8782\n",
      "Epoch 787/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2992 - acc: 0.9991 - val_loss: 0.9306 - val_acc: 0.8850\n",
      "Epoch 788/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3011 - acc: 0.9963 - val_loss: 0.8083 - val_acc: 0.9120\n",
      "Epoch 789/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3016 - acc: 0.9963 - val_loss: 0.8470 - val_acc: 0.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3003 - acc: 0.9972 - val_loss: 0.8252 - val_acc: 0.9075\n",
      "Epoch 791/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3025 - acc: 0.9943 - val_loss: 0.8577 - val_acc: 0.9098\n",
      "Epoch 792/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3132 - acc: 0.9963 - val_loss: 1.1779 - val_acc: 0.8346\n",
      "Epoch 793/1000\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.3024 - acc: 0.9954 - val_loss: 0.8794 - val_acc: 0.8992\n",
      "Epoch 794/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3011 - acc: 0.9980 - val_loss: 1.1928 - val_acc: 0.8323\n",
      "Epoch 795/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3062 - acc: 0.9936 - val_loss: 0.8398 - val_acc: 0.9008\n",
      "Epoch 796/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2998 - acc: 0.9954 - val_loss: 0.8917 - val_acc: 0.8977\n",
      "Epoch 797/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2971 - acc: 0.9991 - val_loss: 0.8944 - val_acc: 0.8985\n",
      "Epoch 798/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2932 - acc: 0.9982 - val_loss: 0.7887 - val_acc: 0.9158\n",
      "Epoch 799/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2970 - acc: 0.9963 - val_loss: 0.7931 - val_acc: 0.9203\n",
      "Epoch 800/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.3033 - acc: 0.9934 - val_loss: 1.0428 - val_acc: 0.8594\n",
      "Epoch 801/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3017 - acc: 0.9952 - val_loss: 0.9675 - val_acc: 0.8737\n",
      "Epoch 802/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3025 - acc: 0.9936 - val_loss: 0.8364 - val_acc: 0.9135\n",
      "Epoch 803/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.3008 - acc: 0.9952 - val_loss: 0.8989 - val_acc: 0.8812\n",
      "Epoch 804/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2941 - acc: 0.9972 - val_loss: 1.0557 - val_acc: 0.8466\n",
      "Epoch 805/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2961 - acc: 0.9982 - val_loss: 1.1263 - val_acc: 0.8338\n",
      "Epoch 806/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2967 - acc: 0.9954 - val_loss: 0.8929 - val_acc: 0.8835\n",
      "Epoch 807/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2972 - acc: 0.9961 - val_loss: 0.8290 - val_acc: 0.9060\n",
      "Epoch 808/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2986 - acc: 0.9963 - val_loss: 0.9539 - val_acc: 0.8684\n",
      "Epoch 809/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2952 - acc: 0.9963 - val_loss: 0.8138 - val_acc: 0.9023\n",
      "Epoch 810/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2959 - acc: 0.9963 - val_loss: 0.8109 - val_acc: 0.9098\n",
      "Epoch 811/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2984 - acc: 0.9945 - val_loss: 0.8248 - val_acc: 0.9083\n",
      "Epoch 812/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2941 - acc: 0.9982 - val_loss: 0.7580 - val_acc: 0.9203\n",
      "Epoch 813/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2941 - acc: 0.9982 - val_loss: 0.8046 - val_acc: 0.9038\n",
      "Epoch 814/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.3019 - acc: 0.9934 - val_loss: 0.8195 - val_acc: 0.9098\n",
      "Epoch 815/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3028 - acc: 0.9943 - val_loss: 0.9972 - val_acc: 0.8617\n",
      "Epoch 816/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2961 - acc: 0.9991 - val_loss: 0.8737 - val_acc: 0.8917\n",
      "Epoch 817/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3070 - acc: 0.9926 - val_loss: 0.9550 - val_acc: 0.8759\n",
      "Epoch 818/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2999 - acc: 0.9945 - val_loss: 1.0442 - val_acc: 0.8474\n",
      "Epoch 819/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2983 - acc: 0.9945 - val_loss: 1.0429 - val_acc: 0.8647\n",
      "Epoch 820/1000\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.2941 - acc: 0.9972 - val_loss: 1.1236 - val_acc: 0.8504\n",
      "Epoch 821/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.3034 - acc: 0.9945 - val_loss: 0.9760 - val_acc: 0.8842\n",
      "Epoch 822/1000\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.3052 - acc: 0.9926 - val_loss: 1.0998 - val_acc: 0.8647\n",
      "Epoch 823/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.3147 - acc: 0.9860 - val_loss: 0.8781 - val_acc: 0.8992\n",
      "Epoch 824/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.3089 - acc: 0.9954 - val_loss: 0.8699 - val_acc: 0.8977\n",
      "Epoch 825/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2987 - acc: 0.9961 - val_loss: 0.8938 - val_acc: 0.8970\n",
      "Epoch 826/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2965 - acc: 0.9982 - val_loss: 0.8903 - val_acc: 0.8910\n",
      "Epoch 827/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2925 - acc: 0.9991 - val_loss: 0.8131 - val_acc: 0.9053\n",
      "Epoch 828/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2982 - acc: 0.9945 - val_loss: 0.8397 - val_acc: 0.9015\n",
      "Epoch 829/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2984 - acc: 0.9963 - val_loss: 0.7991 - val_acc: 0.9158\n",
      "Epoch 830/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2948 - acc: 0.9963 - val_loss: 0.7860 - val_acc: 0.9090\n",
      "Epoch 831/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2940 - acc: 0.9982 - val_loss: 0.8157 - val_acc: 0.9000\n",
      "Epoch 832/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2952 - acc: 0.9963 - val_loss: 1.1901 - val_acc: 0.8459\n",
      "Epoch 833/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2902 - acc: 0.9991 - val_loss: 1.0272 - val_acc: 0.8662\n",
      "Epoch 834/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2929 - acc: 0.9954 - val_loss: 1.2270 - val_acc: 0.8444\n",
      "Epoch 835/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.3026 - acc: 0.9936 - val_loss: 0.8627 - val_acc: 0.9045\n",
      "Epoch 836/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2955 - acc: 0.9963 - val_loss: 0.7695 - val_acc: 0.9226\n",
      "Epoch 837/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2902 - acc: 0.9982 - val_loss: 0.7926 - val_acc: 0.9120\n",
      "Epoch 838/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2956 - acc: 0.9963 - val_loss: 0.7710 - val_acc: 0.9248\n",
      "Epoch 839/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2890 - acc: 0.9963 - val_loss: 0.8243 - val_acc: 0.9083\n",
      "Epoch 840/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2950 - acc: 0.9963 - val_loss: 0.8288 - val_acc: 0.9008\n",
      "Epoch 841/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2989 - acc: 0.9936 - val_loss: 0.9409 - val_acc: 0.8684\n",
      "Epoch 842/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2952 - acc: 0.9972 - val_loss: 1.0152 - val_acc: 0.8579\n",
      "Epoch 843/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2853 - acc: 0.9991 - val_loss: 1.0207 - val_acc: 0.8632\n",
      "Epoch 844/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2907 - acc: 0.9972 - val_loss: 0.7705 - val_acc: 0.9256\n",
      "Epoch 845/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2976 - acc: 0.9950 - val_loss: 0.7750 - val_acc: 0.9218\n",
      "Epoch 846/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2964 - acc: 0.9972 - val_loss: 1.2213 - val_acc: 0.8361\n",
      "Epoch 847/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2908 - acc: 0.9972 - val_loss: 0.8378 - val_acc: 0.9030\n",
      "Epoch 848/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2956 - acc: 0.9945 - val_loss: 0.8755 - val_acc: 0.9023\n",
      "Epoch 849/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2918 - acc: 0.9970 - val_loss: 0.9208 - val_acc: 0.8917\n",
      "Epoch 850/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2892 - acc: 0.9982 - val_loss: 0.8404 - val_acc: 0.9045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2915 - acc: 0.9972 - val_loss: 0.8097 - val_acc: 0.9113\n",
      "Epoch 852/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2955 - acc: 0.9945 - val_loss: 0.7876 - val_acc: 0.9180\n",
      "Epoch 853/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2886 - acc: 0.9991 - val_loss: 0.7817 - val_acc: 0.9158\n",
      "Epoch 854/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2883 - acc: 0.9972 - val_loss: 0.8096 - val_acc: 0.9053\n",
      "Epoch 855/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.2854 - acc: 0.9982 - val_loss: 0.8608 - val_acc: 0.8895\n",
      "Epoch 856/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2916 - acc: 0.9954 - val_loss: 0.8986 - val_acc: 0.8812\n",
      "Epoch 857/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2867 - acc: 0.9982 - val_loss: 0.8250 - val_acc: 0.8977\n",
      "Epoch 858/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2855 - acc: 0.9991 - val_loss: 0.8680 - val_acc: 0.8932\n",
      "Epoch 859/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2921 - acc: 0.9972 - val_loss: 0.8849 - val_acc: 0.8992\n",
      "Epoch 860/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2936 - acc: 0.9961 - val_loss: 0.7429 - val_acc: 0.9211\n",
      "Epoch 861/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2912 - acc: 0.9963 - val_loss: 0.7627 - val_acc: 0.9203\n",
      "Epoch 862/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.2954 - acc: 0.9954 - val_loss: 1.0442 - val_acc: 0.8707\n",
      "Epoch 863/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2890 - acc: 0.9972 - val_loss: 1.2607 - val_acc: 0.8331\n",
      "Epoch 864/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2853 - acc: 1.0000 - val_loss: 0.9031 - val_acc: 0.8910\n",
      "Epoch 865/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2889 - acc: 0.9972 - val_loss: 0.8014 - val_acc: 0.9053\n",
      "Epoch 866/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2927 - acc: 0.9945 - val_loss: 0.8209 - val_acc: 0.9083\n",
      "Epoch 867/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2953 - acc: 0.9952 - val_loss: 0.8469 - val_acc: 0.8962\n",
      "Epoch 868/1000\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.2909 - acc: 0.9963 - val_loss: 0.8742 - val_acc: 0.8850\n",
      "Epoch 869/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2921 - acc: 0.9963 - val_loss: 1.0531 - val_acc: 0.8504\n",
      "Epoch 870/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.3040 - acc: 0.9926 - val_loss: 0.8694 - val_acc: 0.9023\n",
      "Epoch 871/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.2942 - acc: 0.9954 - val_loss: 0.8106 - val_acc: 0.9090\n",
      "Epoch 872/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2899 - acc: 0.9963 - val_loss: 0.8525 - val_acc: 0.8880\n",
      "Epoch 873/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2942 - acc: 0.9963 - val_loss: 0.8050 - val_acc: 0.9000\n",
      "Epoch 874/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2954 - acc: 0.9926 - val_loss: 0.8132 - val_acc: 0.9038\n",
      "Epoch 875/1000\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.2896 - acc: 0.9970 - val_loss: 0.7821 - val_acc: 0.9150\n",
      "Epoch 876/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2885 - acc: 0.9972 - val_loss: 0.8181 - val_acc: 0.8962\n",
      "Epoch 877/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2860 - acc: 0.9972 - val_loss: 0.8876 - val_acc: 0.8835\n",
      "Epoch 878/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2925 - acc: 0.9963 - val_loss: 0.8087 - val_acc: 0.9030\n",
      "Epoch 879/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2880 - acc: 0.9982 - val_loss: 0.8656 - val_acc: 0.8955\n",
      "Epoch 880/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2882 - acc: 0.9961 - val_loss: 0.8865 - val_acc: 0.9000\n",
      "Epoch 881/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2925 - acc: 0.9952 - val_loss: 0.8259 - val_acc: 0.9060\n",
      "Epoch 882/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2888 - acc: 0.9970 - val_loss: 0.8413 - val_acc: 0.8925\n",
      "Epoch 883/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2849 - acc: 0.9991 - val_loss: 0.8843 - val_acc: 0.8835\n",
      "Epoch 884/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2846 - acc: 0.9982 - val_loss: 0.8362 - val_acc: 0.9030\n",
      "Epoch 885/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2929 - acc: 0.9945 - val_loss: 0.8883 - val_acc: 0.8895\n",
      "Epoch 886/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2874 - acc: 0.9954 - val_loss: 0.8815 - val_acc: 0.8940\n",
      "Epoch 887/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2909 - acc: 0.9963 - val_loss: 1.2360 - val_acc: 0.8263\n",
      "Epoch 888/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2862 - acc: 0.9959 - val_loss: 1.2066 - val_acc: 0.8383\n",
      "Epoch 889/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2860 - acc: 0.9970 - val_loss: 0.9288 - val_acc: 0.8872\n",
      "Epoch 890/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2844 - acc: 0.9982 - val_loss: 0.7868 - val_acc: 0.9150\n",
      "Epoch 891/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2840 - acc: 0.9982 - val_loss: 0.7847 - val_acc: 0.9135\n",
      "Epoch 892/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2892 - acc: 0.9948 - val_loss: 0.7977 - val_acc: 0.9008\n",
      "Epoch 893/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2889 - acc: 0.9963 - val_loss: 0.8210 - val_acc: 0.8962\n",
      "Epoch 894/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.2905 - acc: 0.9945 - val_loss: 0.7942 - val_acc: 0.9143\n",
      "Epoch 895/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2983 - acc: 0.9936 - val_loss: 0.7963 - val_acc: 0.9158\n",
      "Epoch 896/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2919 - acc: 0.9954 - val_loss: 1.1950 - val_acc: 0.8346\n",
      "Epoch 897/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2843 - acc: 0.9982 - val_loss: 1.1586 - val_acc: 0.8376\n",
      "Epoch 898/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2910 - acc: 0.9941 - val_loss: 0.8497 - val_acc: 0.8970\n",
      "Epoch 899/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2897 - acc: 0.9945 - val_loss: 0.8124 - val_acc: 0.9053\n",
      "Epoch 900/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2838 - acc: 0.9963 - val_loss: 0.9987 - val_acc: 0.8647\n",
      "Epoch 901/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.2901 - acc: 0.9945 - val_loss: 0.8351 - val_acc: 0.8985\n",
      "Epoch 902/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2936 - acc: 0.9963 - val_loss: 0.7840 - val_acc: 0.9165\n",
      "Epoch 903/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2893 - acc: 0.9961 - val_loss: 0.7918 - val_acc: 0.9023\n",
      "Epoch 904/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2832 - acc: 0.9963 - val_loss: 0.7977 - val_acc: 0.9008\n",
      "Epoch 905/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2841 - acc: 0.9982 - val_loss: 0.7985 - val_acc: 0.9045\n",
      "Epoch 906/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2827 - acc: 0.9991 - val_loss: 0.7663 - val_acc: 0.9068\n",
      "Epoch 907/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2891 - acc: 0.9963 - val_loss: 0.9900 - val_acc: 0.8579\n",
      "Epoch 908/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2856 - acc: 0.9972 - val_loss: 0.8264 - val_acc: 0.8977\n",
      "Epoch 909/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2893 - acc: 0.9972 - val_loss: 0.7848 - val_acc: 0.9053\n",
      "Epoch 910/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2825 - acc: 0.9970 - val_loss: 0.8174 - val_acc: 0.9045\n",
      "Epoch 911/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2843 - acc: 0.9972 - val_loss: 0.7990 - val_acc: 0.9060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2821 - acc: 0.9991 - val_loss: 0.7848 - val_acc: 0.9120\n",
      "Epoch 913/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2844 - acc: 0.9963 - val_loss: 0.7663 - val_acc: 0.9211\n",
      "Epoch 914/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2845 - acc: 0.9963 - val_loss: 0.8421 - val_acc: 0.8857\n",
      "Epoch 915/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2883 - acc: 0.9936 - val_loss: 0.7695 - val_acc: 0.9195\n",
      "Epoch 916/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2829 - acc: 0.9982 - val_loss: 0.9455 - val_acc: 0.8850\n",
      "Epoch 917/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2874 - acc: 0.9972 - val_loss: 0.9812 - val_acc: 0.8654\n",
      "Epoch 918/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2901 - acc: 0.9943 - val_loss: 0.8402 - val_acc: 0.8962\n",
      "Epoch 919/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2873 - acc: 0.9972 - val_loss: 0.9237 - val_acc: 0.8692\n",
      "Epoch 920/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2833 - acc: 0.9963 - val_loss: 0.8851 - val_acc: 0.8857\n",
      "Epoch 921/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2808 - acc: 0.9982 - val_loss: 0.9342 - val_acc: 0.8782\n",
      "Epoch 922/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2830 - acc: 0.9963 - val_loss: 0.8289 - val_acc: 0.9000\n",
      "Epoch 923/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2869 - acc: 0.9954 - val_loss: 0.8465 - val_acc: 0.9038\n",
      "Epoch 924/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2818 - acc: 0.9970 - val_loss: 0.8352 - val_acc: 0.9090\n",
      "Epoch 925/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2796 - acc: 0.9991 - val_loss: 0.8965 - val_acc: 0.8977\n",
      "Epoch 926/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2804 - acc: 0.9982 - val_loss: 0.9136 - val_acc: 0.8940\n",
      "Epoch 927/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2817 - acc: 0.9963 - val_loss: 0.8758 - val_acc: 0.9000\n",
      "Epoch 928/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2789 - acc: 0.9982 - val_loss: 0.8758 - val_acc: 0.9000\n",
      "Epoch 929/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2817 - acc: 0.9963 - val_loss: 0.8914 - val_acc: 0.8977\n",
      "Epoch 930/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2784 - acc: 0.9980 - val_loss: 0.8720 - val_acc: 0.9008\n",
      "Epoch 931/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2814 - acc: 0.9982 - val_loss: 0.8218 - val_acc: 0.9128\n",
      "Epoch 932/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2815 - acc: 0.9972 - val_loss: 0.7889 - val_acc: 0.9098\n",
      "Epoch 933/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2759 - acc: 0.9982 - val_loss: 0.7908 - val_acc: 0.9053\n",
      "Epoch 934/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2798 - acc: 0.9972 - val_loss: 0.7868 - val_acc: 0.9120\n",
      "Epoch 935/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2825 - acc: 0.9961 - val_loss: 0.7919 - val_acc: 0.9045\n",
      "Epoch 936/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2869 - acc: 0.9972 - val_loss: 0.8879 - val_acc: 0.8805\n",
      "Epoch 937/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2804 - acc: 0.9991 - val_loss: 0.8018 - val_acc: 0.9075\n",
      "Epoch 938/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2822 - acc: 0.9972 - val_loss: 0.9131 - val_acc: 0.8812\n",
      "Epoch 939/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2812 - acc: 0.9963 - val_loss: 0.9365 - val_acc: 0.8714\n",
      "Epoch 940/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2775 - acc: 1.0000 - val_loss: 0.9009 - val_acc: 0.8774\n",
      "Epoch 941/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2814 - acc: 0.9963 - val_loss: 0.8278 - val_acc: 0.8985\n",
      "Epoch 942/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2826 - acc: 0.9963 - val_loss: 0.7915 - val_acc: 0.9075\n",
      "Epoch 943/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2792 - acc: 0.9980 - val_loss: 0.8572 - val_acc: 0.8880\n",
      "Epoch 944/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2763 - acc: 0.9972 - val_loss: 0.8733 - val_acc: 0.8887\n",
      "Epoch 945/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2778 - acc: 0.9982 - val_loss: 0.8233 - val_acc: 0.9128\n",
      "Epoch 946/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2787 - acc: 0.9972 - val_loss: 0.8091 - val_acc: 0.9135\n",
      "Epoch 947/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2829 - acc: 0.9963 - val_loss: 0.8194 - val_acc: 0.9098\n",
      "Epoch 948/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2803 - acc: 0.9982 - val_loss: 0.9178 - val_acc: 0.8744\n",
      "Epoch 949/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2798 - acc: 0.9952 - val_loss: 0.7841 - val_acc: 0.9083\n",
      "Epoch 950/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2817 - acc: 0.9972 - val_loss: 0.7600 - val_acc: 0.9195\n",
      "Epoch 951/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2750 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.9211\n",
      "Epoch 952/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2791 - acc: 0.9972 - val_loss: 0.9092 - val_acc: 0.8977\n",
      "Epoch 953/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2798 - acc: 0.9972 - val_loss: 0.9848 - val_acc: 0.8812\n",
      "Epoch 954/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2840 - acc: 0.9963 - val_loss: 0.8914 - val_acc: 0.8827\n",
      "Epoch 955/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2808 - acc: 0.9972 - val_loss: 0.9357 - val_acc: 0.8677\n",
      "Epoch 956/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2865 - acc: 0.9936 - val_loss: 0.8019 - val_acc: 0.9090\n",
      "Epoch 957/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2756 - acc: 0.9982 - val_loss: 0.8245 - val_acc: 0.9083\n",
      "Epoch 958/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2751 - acc: 1.0000 - val_loss: 0.9480 - val_acc: 0.8797\n",
      "Epoch 959/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2769 - acc: 0.9963 - val_loss: 0.8234 - val_acc: 0.9068\n",
      "Epoch 960/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2805 - acc: 0.9943 - val_loss: 0.8004 - val_acc: 0.8962\n",
      "Epoch 961/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2787 - acc: 0.9982 - val_loss: 0.8421 - val_acc: 0.8865\n",
      "Epoch 962/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2801 - acc: 0.9963 - val_loss: 0.8303 - val_acc: 0.8985\n",
      "Epoch 963/1000\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.2800 - acc: 0.9954 - val_loss: 0.8158 - val_acc: 0.9068\n",
      "Epoch 964/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2757 - acc: 0.9991 - val_loss: 0.8046 - val_acc: 0.9158\n",
      "Epoch 965/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2797 - acc: 0.9945 - val_loss: 0.8934 - val_acc: 0.8970\n",
      "Epoch 966/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2774 - acc: 0.9961 - val_loss: 1.8213 - val_acc: 0.7759\n",
      "Epoch 967/1000\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 0.2780 - acc: 0.9972 - val_loss: 1.5262 - val_acc: 0.8000\n",
      "Epoch 968/1000\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 0.2800 - acc: 0.9972 - val_loss: 1.2069 - val_acc: 0.8444\n",
      "Epoch 969/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.2802 - acc: 0.9945 - val_loss: 1.1180 - val_acc: 0.8556\n",
      "Epoch 970/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2789 - acc: 0.9972 - val_loss: 1.8896 - val_acc: 0.7699\n",
      "Epoch 971/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2753 - acc: 0.9982 - val_loss: 1.3544 - val_acc: 0.8278\n",
      "Epoch 972/1000\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 0.2730 - acc: 0.9991 - val_loss: 1.1442 - val_acc: 0.8519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2713 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.9053\n",
      "Epoch 974/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2722 - acc: 1.0000 - val_loss: 0.7988 - val_acc: 0.9158\n",
      "Epoch 975/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2698 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.9241\n",
      "Epoch 976/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2729 - acc: 0.9982 - val_loss: 0.8894 - val_acc: 0.8925\n",
      "Epoch 977/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2762 - acc: 0.9982 - val_loss: 0.7777 - val_acc: 0.9128\n",
      "Epoch 978/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2712 - acc: 0.9982 - val_loss: 0.7672 - val_acc: 0.9150\n",
      "Epoch 979/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2718 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.9128\n",
      "Epoch 980/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2719 - acc: 0.9991 - val_loss: 0.7538 - val_acc: 0.9180\n",
      "Epoch 981/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2762 - acc: 0.9952 - val_loss: 0.7740 - val_acc: 0.9128\n",
      "Epoch 982/1000\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.2745 - acc: 0.9980 - val_loss: 0.7864 - val_acc: 0.9150\n",
      "Epoch 983/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2819 - acc: 0.9952 - val_loss: 0.8108 - val_acc: 0.8992\n",
      "Epoch 984/1000\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 0.2760 - acc: 0.9963 - val_loss: 0.8562 - val_acc: 0.8940\n",
      "Epoch 985/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2767 - acc: 0.9972 - val_loss: 1.1244 - val_acc: 0.8383\n",
      "Epoch 986/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2720 - acc: 0.9991 - val_loss: 1.1539 - val_acc: 0.8331\n",
      "Epoch 987/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2714 - acc: 0.9991 - val_loss: 1.0270 - val_acc: 0.8504\n",
      "Epoch 988/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2724 - acc: 0.9982 - val_loss: 0.8987 - val_acc: 0.8737\n",
      "Epoch 989/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2786 - acc: 0.9954 - val_loss: 0.8571 - val_acc: 0.8887\n",
      "Epoch 990/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2887 - acc: 0.9945 - val_loss: 1.1265 - val_acc: 0.8549\n",
      "Epoch 991/1000\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.2948 - acc: 0.9936 - val_loss: 1.0687 - val_acc: 0.8429\n",
      "Epoch 992/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2733 - acc: 0.9991 - val_loss: 0.8677 - val_acc: 0.8895\n",
      "Epoch 993/1000\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.2772 - acc: 0.9961 - val_loss: 1.6679 - val_acc: 0.7902\n",
      "Epoch 994/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2740 - acc: 0.9980 - val_loss: 1.4709 - val_acc: 0.8105\n",
      "Epoch 995/1000\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.2713 - acc: 0.9980 - val_loss: 0.8225 - val_acc: 0.9023\n",
      "Epoch 996/1000\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.2753 - acc: 0.9972 - val_loss: 0.7327 - val_acc: 0.9211\n",
      "Epoch 997/1000\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.2760 - acc: 0.9963 - val_loss: 1.1741 - val_acc: 0.8444\n",
      "Epoch 998/1000\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 0.2772 - acc: 0.9963 - val_loss: 0.8668 - val_acc: 0.8880\n",
      "Epoch 999/1000\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.2847 - acc: 0.9917 - val_loss: 0.7889 - val_acc: 0.9075\n",
      "Epoch 1000/1000\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 0.2771 - acc: 0.9963 - val_loss: 0.8341 - val_acc: 0.8992\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 38\n",
    "nb_epoch = 1000\n",
    "data_augmentation = True\n",
    "lr_schedule = [40,60,70] # epoch_step\n",
    "def schedule(epoch_idx):\n",
    "    if (epoch_idx + 1) < lr_schedule[0]:\n",
    "        return 0.001 \n",
    "    if (epoch_idx + 1) < lr_schedule[1]:\n",
    "        return 0.0001\n",
    "    if (epoch_idx + 1) < lr_schedule[2]:\n",
    "        return 0.001\n",
    "    return 0.0001\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "model2 = ResNet50_cifar_small(classes = nb_classes)\n",
    "    \n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model2.fit_generator(datagen.flow(train_data, train_label, batch_size=batch_size),\n",
    "                    steps_per_epoch=train_data.shape[0] // batch_size,\n",
    "                    validation_data=(test_data, test_label) ,\n",
    "                    epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                    callbacks=[ LearningRateScheduler(schedule=schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:37:00.908987Z",
     "start_time": "2020-06-13T11:36:56.115800Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.save('resnet50_s_cifar10.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T08:32:38.237554Z",
     "start_time": "2020-06-16T08:32:38.144774Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7f539fdf9cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T07:55:12.757425Z",
     "start_time": "2020-06-16T07:55:12.443316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4HNW5uN9vV92S5SL3grvBGGODMcU4mN5LAiGQcCkJGEKoCQmQAlwSbnrChVAvIZSEFgLBPzAQegmm2EAwtgEXXGRsIzdZXdrd8/vjzGhnR7Orla2V5N3vfZ59dufMmZkzs7vnO1853xFjDIqiKIoCEOruBiiKoig9BxUKiqIoSisqFBRFUZRWVCgoiqIorahQUBRFUVpRoaAoiqK0okJBySlE5D4R+UWadVeJyBGZbpOi9CRUKCiKoiitqFBQlF0QEcnr7jYo2YkKBaXH4ZhtfigiH4lInYj8WUQGicizIlIjIi+KSF9P/ZNEZLGIbBORV0VkD8++aSLyvnPco0CR71oniMiHzrFviciUNNt4vIh8ICLbRWStiNzg23+wc75tzv5znfJiEfm9iKwWkWoRedMpmy0ilQHP4Qjn8w0i8riI/FVEtgPnisgMEZnvXGO9iPxJRAo8x+8pIi+IyBYR2SgiPxaRwSJSLyL9PfX2FZEqEclP596V7EaFgtJTORU4EpgAnAg8C/wYqMD+bi8DEJEJwMPAFcAAYB7w/0SkwOkg/wk8CPQD/u6cF+fYfYB7gQuB/sBdwFwRKUyjfXXA2UAf4HjguyJyinPekU57b3XaNBX40Dnud8C+wEFOm34ExNJ8JicDjzvX/BsQBa50nsmBwOHAxU4byoAXgeeAocA44CVjzAbgVeB0z3nPAh4xxrSk2Q4li1GhoPRUbjXGbDTGrAPeAN4xxnxgjGkCngSmOfW+ATxjjHnB6dR+BxRjO90DgHzgZmNMizHmceA9zzUuAO4yxrxjjIkaY+4HmpzjUmKMedUYs8gYEzPGfIQVTIc4u78FvGiMedi57mZjzIciEgK+DVxujFnnXPMt557SYb4x5p/ONRuMMQuNMW8bYyLGmFVYoea24QRggzHm98aYRmNMjTHmHWff/VhBgIiEgTOxglNRVCgoPZaNns8NAdulzuehwGp3hzEmBqwFhjn71pnErI+rPZ93A37gmF+2icg2YIRzXEpEZH8RecUxu1QDF2FH7DjnWBFwWAXWfBW0Lx3W+towQUSeFpENjknpf9JoA8BTwCQRGYPVxqqNMe/uYJuULEOFgrKr8wW2cwdARATbIa4D1gPDnDKXkZ7Pa4GbjDF9PK8SY8zDaVz3IWAuMMIYUw7cCbjXWQuMDThmE9CYZF8dUOK5jzDW9OTFn9L4DuATYLwxpjfWvNZeGzDGNAKPYTWa/0K1BMWDCgVlV+cx4HgROdxxlP4AawJ6C5gPRIDLRCRPRL4GzPAc+3/ARc6oX0Skl+NALkvjumXAFmNMo4jMAL7p2fc34AgROd25bn8RmepoMfcCfxCRoSISFpEDHR/GZ0CRc/184KdAe76NMmA7UCsiuwPf9ex7GhgsIleISKGIlInI/p79DwDnAicBf03jfpUcQYWCsktjjPkUax+/FTsSPxE40RjTbIxpBr6G7fy2Yv0PT3iOXYD1K/zJ2b/cqZsOFwM3ikgNcB1WOLnnXQMchxVQW7BO5r2d3VcBi7C+jS3Ar4GQMabaOec9WC2nDkiIRgrgKqwwqsEKuEc9bajBmoZOBDYAy4BDPfv/jXVwv+/4IxQFANFFdhQlNxGRl4GHjDH3dHdblJ6DCgVFyUFEZD/gBaxPpKa726P0HNR8pCg5hojcj53DcIUKBMWPagqKoihKK6opKIqiKK3sckm1KioqzKhRo7q7GYqiKLsUCxcu3GSM8c99acMuJxRGjRrFggULursZiqIouxQisrr9Wmo+UhRFUTyoUFAURVFaUaGgKIqitLLL+RSCaGlpobKyksbGxu5uSkYpKipi+PDh5OfrWiiKomSGrBAKlZWVlJWVMWrUKBITYmYPxhg2b95MZWUlo0eP7u7mKIqSpWTMfCQi94rIlyLycZL9IiK3iMhyscsu7rOj12psbKR///5ZKxAARIT+/ftnvTakKEr3kkmfwn3AMSn2HwuMd15zsLnhd5hsFgguuXCPiqJ0LxkzHxljXheRUSmqnAw84KyK9baI9BGRIcaY9Zlqk6J0BvXNEcIhoSAcSiqo65oi9CpM7+9ljKGxJUZxQbjduo0tUYry4/Xc69Q1RRCB5kiM1ZvrmTi4LKFeY0sUgMK8eJubIlEK88I0tkSJGcPaLQ1MHFxGNGbYUtdMRWkBVTVNPL94A8dPGUq/XgWt58oPh+y1ttSx++DeAMRihuZojOZojFWb6pgwKLEN7r3+fWEljS1RDhjTn5H9SijKD/PZxhoWrt7KrPEVDO9bQmNLlM831VHXFGHMgFI21zYxop9dg2jtlnr6lxbStySfxpYYRfkhNtU2s6G6kUlDexMOCas311FcEGZjdRPD+xZTVpTH6i31DCgrpCAcYn11I2ERNtc1Mah3ER+vq+aoPQcnPK/Ndc1EojGG9SmmrilK7+I8GlqilBTkUbm1npAIzZEYfUsKKCkME40Z1mypp7Qwj/xwiIK8EB+vq2bNlnqO2GMQJQVhXvusiumj+rJ43XaG9ikmEosxdkApW+qaeeL9SnoV5lGUH+aEKUP4cO02xg0spaqmibEDStP+Pe0s3elTGEbi8oKVTlkboSAic7DaBCNHjvTv7na2bdvGQw89xMUXX9yh44477jgeeugh+vTpk6GWdQ+NLVEiMUOp8yN2O52YgfywUJiX2FlFY4ZehXk0RaJEojYXVzgkbToUl989/ymfbazh8iPG8/6abZw4ZQirN9dTmB/i0oc+4IaT9mTmOLsq5ebaJh5dsJbhfUv40eP/4fLDJzBuYCnPLlrPN/YbwS+eWcqg3oVcMGsM4weV8dA7qxnRr4R9RvaltinCa59V8fbKzeSFhKqaJj5aV403Xdhb1xzGPxZW8u6qLVx++Hj+/ObnGAPPLd4AwJTh5dQ2RVhZVcdfztuPh95ZwwtL7Mqiw/sWc+lh47j6H4sAOGbPwTRFokwYVMbW+mZOmTaMv729hmcW2b9EflhoiabOVTa0vIgvqhsZN7CUb84YyfKqWqpqmlqvWVIQZnB5EfVNUTZsT98U+bOnFnP0noNYX93IR5XVCftO3Wc4G7c38ubyTW2OmzColPMPHsO/lmygJWrYUN3IpxsTc/AN6l3Ixu3xZaqPnTyYZz/ekHbb/Bw6cQCvfFq1w8f7KcwL0RSJ7dQ5rmVRx+o/EVz/rv/al6M9wisTZDQhnqMpPG2MmRyw7xngl8aYN53tl4AfGWMWpjrn9OnTjX9G89KlS9ljjz06q9kdZtWqVZxwwgl8/HGi+yQajRIOtz/66widea+LKqtZuamWk6cOS1rn9c+q2GtYOS2xGE0tMcIhYWifYh6Yv4o+JQW8uayKCw8ZizGG5V/W8VHlNm5/dQXlxfl88LMj+Z95S7nnzc9bzzeiXzE3njSZD9Zu41+LN/DJhhryQsJB4yp4/TP7R64oLaCkII89hpTx/GLbmYUEYgZ6F+WxvTHS7r3NGN2PY/YczI1PL9m5h5SjTBrSm3XbGqhuaOm0cxblh2hsiTFmQC9WVtUl7BvWp5h12xraHFNenN9uG8qK8qhJ4zcRRN+SfEIibK5rTlpn7IBerPC1t09JPuMH2hG+d19BntWgZo23g5IP12yjpinCmIperNyUeA4v5cX5PDLnADvYeeRDAGaNr+CNZYmC9t5zp3PY7oM6fJ8AIrLQGDO9vXrdqSlUYtfSdRmOXW93l+Oaa65hxYoVTJ06lfz8fEpLSxkyZAgffvghS5Ys4ZRTTmHt2rU0NjZy+eWXM2fOHCCesqO2tpZjjz2Wgw8+mLfeeothw4bx1FNPUVxc3GltNMZgDKyoquXShz/gsN0Hcvurdl13v1D4fFMdn2+qZfzAMs6+t+167oftPpCXP/mydfuxBW0XCKtuaGHMj+e1KV+7pYHz7nsvoSwSM60CAWBTbTPQzJot9a1lMWfs4hUIIpBsTPPu51t49/MtwTsdDhzTn0gsxnurtqasd+EhYxg7oJTtDS3cNG8pB4+r4KPKahpboklHkM9dMYtfPfsJlx0+npVVdVz19/+07nvqezMpL85n9u9ebS07ffpwTtp7GOMGlvLuqi387vlPWbOlnsN2H8i39h/JfW+t4v3VW3n6slksWLWF0/Ydzua6ZvJCQkFeiOqGFg785csAfHjdkdz84jJWVNUyaWhv5swaQ79eBazeXM+tLy/n6mMnUlaYTyQWY0VVHQ+/s4bB5UV8d/ZYFn+xncnDelOYF6YlGiNmDIV5YTbVNnH8LW+QFwpx/qzRFOeHmTayL0ff/DoA/7ryKxSEQ7y+rIpfPLOUV66aTVlRHuf95T2aIzF+feoUxg0sZcn67YwbWEppYV6riWhY32J6F+VT1xTho8pqbn7xM47bawhnH7hbgnmuOWJNUxu3N9LQHKWxJcr0Uf0wjunrtWVVxGKG6+cupk9JPm9efRiFeSE+3VDDyP4lfLGtgYmDyqhpihASadVkARqaoyxZX82KqjoKwiFOmWb/E/XNEYodjfX9NVsZXF5M35J8Sgrixy5dv52+JQUM6l2Ylt+vrinCmi31jK7oRUiEvJDQHI1RlB9mjyG9E/6PqzbV0bs4n231zdz31ioOHtdu6qKdpjs1heOBS7DLFu4P3GKMmeGv56c9TeG//99ilnyxfafb7mXS0N5cf+KeSfd7NYVXX32V448/no8//rg1dHTLli3069ePhoYG9ttvP1577TX69++fIBTGjRvHggULmDp1KqeffjonnXQSZ511Vptree/19c+quPv1ldx33n7khdvGDFTVNFFSEOaZRetZvK6a++cHpz6ZMrycYyYP5tVPqmhoibJoXXVgvR1lcO8ipo/qy/bGSELn/9vTprB0fQ2HTBzAOQHCx8sbPzqUCx9cyJL12/nJcXtw6O4DGTewlA/WbOW9VVs4b+Zo/rN2G6fdOb/Nsb/62l6cuu9wjIEJP32WIycN4v/Ojg+YYjFDfUuULbXNDOtbzIbtjfQqCPO3d9ZQUVrAN/ZLbrKMRGOERHh9WRUNzVEmDi5j3bYGZo1P/PO6HdfarfWtpq365giTrnueM2eM4Jdfm5JQv6qmibtfX8EPjppIUX4Y45jfwqHknc7H66r59/JNXHjI2JTPckeJxQwiiQEPbv/RU4IgojHDpQ+/z7f23631OSuWbtcURORhYDZQISKVwPVAPoAx5k5gHlYgLAfqgfMy1ZauZsaMGQlzCW655RaefPJJANauXcuyZcvo379/wjGjR49m6tSpAOy7776sWrUKgGjMdjpBfzp3FH/0za9z7szR3P36CmZPGMinG2vaHSV7+aiyuo2dOIgnLj6I6oYWYjHDpxtrGNmvhBmj+vHIe2s5ffoIBpcX8f6arQwsK+TUO95qtRPPv/YwRIRINMa4nzwLwAlThnDKtGF8fboVZm/86FCGlBfx7qotLFi1lSHlRfz17dVcdfREDhzTn7xwiGcuO7jNc5g2si/TRvYFYPqofiy98RjqmiNUlBYSixleXLqRI/YYRMjpTN/58eH0KUmc/BcK2VGjO3Ic1sdqaN87dFy7z8QVxrMnDmwtGzOgtE09EWFk/xJG9i9pLSspyOOdHx/e6sD1MqCskJ8cPynh+HA7/e7kYeVMHlbebpt3lFCAQOopwsAlHBJu/9a+3d2MXZpMRh+d2c5+A3yvs6+bakTfVfTq1av186uvvsqLL77I/PnzKSkpYfbs2YFzDQoLC1s/h8NhGhoaiMZiLP5iOwPLihhcXoQxhm31zZx+53y8/8UVVXX87J/Wn/Hg2+0nQhw7oBcbqhupa45SmBfissPHM6CskMcXVLLHkDJKCvP4+4JKNtU28b1Dx3LbKyuYOqIP+zidL8Dhe8TtmpcdPr71s1vnz+fsx8PvruHGkye3dhx54RBPX3oww/sW06cksSN0I0sOGlvBQWPtCO/r00ck1EmnAyouCLdG8YRCkhBRAjCod1G75+hKelp7FCUrZjR3N2VlZdTUBK9qWF1dTd++fSkpKeGTTz7h7bffTnmuL2saaYlaO7UbabK1vpnSwjDNUUNtU5R3V6WvBfz3SXsSiRnmLVrPvefsx4eV25g6og/b6pspzg8z0NMpne7phC/8yhi21rewW78SLjxkLCVJIoGSMXlYOTd9da/AckVRei4qFDqB/v37M3PmTCZPnkxxcTGDBsVH0ccccwx33nknU6ZMYeLEiRxwwAGB5zAG1lc3UFXTxKaaZgqJ8pkTutcSjQVGLtxz9nRWba6jf2kBVz4ad2Sesd8IHnnPRvuec9AoAL5zsDVnHTLB2rrLi1PnT+pTUtA6mu9dpLmWFCVXUKHQSTz00EOB5YWFhTz77LOB+1atWsUX2xoo7lfKw8+/SVWNtcGfc9El7V7vsN0HcsSkuPA5aGwFP3nyY15cupGfnzKZZxatJ9TD7L2KovR8VCh0EyuraqlrimJIP/qrOD9MRakdvR84JtFRPah3EXf/175sa2ghPxzi3R8f0antVRQlN1ChkGGaI3bClxtKuKWuiaZIjNqm1JNtSgvz6FNSQHFBmGWOGWn8oDKWbgkz95KZ7BVgmw+FpDWSJZ2UCYqiKH5UKGSImDE0R2J8trGGkoI8xg0sxRhD5da2sza9VJQWMri8KMH0M6CskIK8+DyEKcOzKy2Goig9BxUKGWJDdSObaq2PoL45QnMkyicbgiOUAIrybWKyoX3azmIeUt55M5sVRVFSoUIhA8SMaRUILskEwsTBZeSFQhhjWkNRFUVRugtdo7mTMcaw4svapPu9k5VKC/MozAsTDgl54RDFBSqjFaXTMQZiMWiqgZqN3d2aHo8KhU5g27Zt3H777QB8trGGBid3vZfd+vdiyvA+DOpdxPhBZYBNyXvzzTdTX1/fpr6i9AhiUZh7KSx5aufP1bAN3n8QmmqhZSdXEKz3TOA0JnHbizHwq93gxr7w0Dfg9xMg4smIuv0L2Lxi59rRkeO/+MDefxBzL4Mn5rQtNwbWvb9j7dsBVCh0Aq5Q2N7Q0iZr5pThfZgyvE/CZLHi/DCjK3oxpLxYhYLSs1n+Erz/ALzyP+3XrdsM79wFn7TNjgvAfcfD3Evgl8PgpkHwjwvsCN4Y+7qhHP79v+1fZ/7t8JvRsNVJ6fLu3XZ725rEeltWQs16aHLyeq3+t33/4gN46hLY8jk8djbcug+0eAJAYj4zrjFWkGxZCdEIVC6EOiel9W0z7PFv/L79dq95G+6eDfNvi5dtWwNRJzX4+/fDR4/atnnv5a1b4P8OhdVtkz1mAhUKncD3rvgBy1esYMb0ffjDL37GfXfeyjePP4zTjpzJ9ddfD0BdXR3HH388e++9N5MnT2beU0/wpz/dyhdffMGhhx7KoYce2s13oXQrDds6Vr9mA2xb27Z862q47wS4eS949up2rulJGb70afjL8dbE4uWhr9v3Rl/CxOUvwSfPJJY9cDI8+yN45MzEThbgr6fBRt9y7YsesyP4134db8sL19l3Y6C5Hn4zBu442HaIa96x+179ldO2b9hO+qNH7bb3eVQuhFumBXfWy/4FHzwIT14ElU4ad/e+qz6zbfr0uXj9V26CXwyw5/voEbjnMLjHmQdU52T9fenGeP1YFF7+Bbz+27hWsvB+uPdo5xqf2PfaKvs9vfTf9j5cPnjQlru4wqB+c9t7yQDZZ8R+9hrY0LFVjtpl8F5w7K8Cd0VjMS65+no+XbqEx55/g7dee5l3X57HG2/NJ2YM55xxGq+//jpVVVUMHTqUZ56xf6Tq6mrKy8v5wx/+wCuvvEJFhab5zQjRCFSvhX6jE8ubauBfP4PDr4OSfrYsFrN1++4WfK7V88HEYNRMz/lb4L17YL/zIexog6/8EgpKYPAUGNuOsP/gb9BcazvTPrvBlG/AzMuh0JNptWYjbK+EYZ7sn7+faN+/8iPIL4ZZ37fba+bDqjfs53futPt/OwZGHmQXoDj5NvssPn8D7j8BznoCeg+DR79lj3n+xxDKh1k/gHLPOhvuvUVb4Llr7D0D3OARFhs9/7uqT2Ho1Pj28heSP4NXfwl7fjW+vXmF1Uw+ftxu12+GvzjLve93fnzkX7UUVr8J65x1uf76Nfip4zPY6izstPD+ttdb4+Qfi3gE14v/bZ/Lyz+320ueggETbZn3HOv/Ez//Fx8mnre6Ep640H4Xr//Wlr1zF5x6D/y/y+L1Vv8bbjsA9jjBbn/+Omxd1bad0QiE8+IC+ePHYffjIcOZCrJPKHQx/lWh5r/+Cq+99CKHztwfgNraWpYtW8asWbO46qqruPrqqznhhBOYNWtWdzQ3+2iqhXAB5DlZV9e9D18uhWnfsqPNW6dZVfyyD6DfmPhxD34NKt+F4j5wxA227N27bId3yp2w19fBRCEWgQIn663bMV2ywF6z91B4+w544WeAwAEXWRvza54BxDVrQEJQaP1IRJrsSLKgxAqmpzxLuG5bDa//BpY9b9swyEmd/fi3bed30q2wz9mJKwu9/hv77gqFGt9qtu5IeM1b9v2tW2HA7lZgAHz4N/j4H/H67z9g3zcsgkknxcvDThbf9++PCwSwbRGxQsBLsydXVzpa0F9Pi39+/sfw2XPB9bzXBquduEQ8fop/fMe+xwJWbVv9pn3f7lnT68O/Jtb5z0P2Ne2/7G+kzllU6t2743XuPiTxmJdutOcOe3KF1VUlthGgdqN9VS212yUVsHl5fP+4I60Qrd8EZYOhyVkfZvGTcMDFMKLdZWd2iuwTCklG9JmioTnuVLarMRmuvuYavnvRRW3qLly4kHnz5nHttddy1FFHcd1113VhS3cRPnwYxsyG3kMSy1f9G4p62xHVor/D6Q/YDvg3o2HGHDjOGZn9nzMyH3mAHXG6ttmtq6z5YdnzMP4oKxDAjsLqNsHGxfER5z8vshrD8hdh7Tvw/aXwj/PjbfmTs07JsOmw24H288pX7OjysJ8mtvuvp8Y75gnHwmdOHqwjbrBaRxDr/wN3HGhH4X/7erwTm3sp9B0dPFJ0O2d/dE21z8T00WPQ7DEReQWCl8p3488I7Mj4hnIoKEus99atMPMya1v30uLxk63/D+1S7bGhewXC4L3S1/zze9nn8NDp6dWvS2Md5w8ehOJ+6Z3P/f2sfCW9+i75xVZbdKmYYIVCzXorFLwCdstKFQo9nZaooW95b1oa6xk7oBdnfPUEbrj+ev7rrLMoLS1l3bp15OfnE4lE6NevH2c55ffddx8QT7udNeaj5jprfshru3BMApuWw5+PhAtegsLe8P8ut2aTf14EQ/eBOZ4/1spX2462oi3xDu+9e+JCweXWfRK3X7wh3jktfjJe/uVSW7exGqZ6Vrrb9JkVCACL/xl3UnpZt8C+IN6R+TvZSs/So595EiO+eEPb8/mpXGjt317uPyG47uYVUDHOdhpe5l2VuN2cfAIlJRV2dOpHwlZjCjr+03kwuM3CiomdXDpCIRnN9XD49dbunoqKCfY7a9re9pkBlA1pq0WlS0OKVPV5RXENxTva3/tM+M/D6Z2/sdpqkC7DnN/u2ndh6LTEuqU7tj5zR1BH804SiRkGDqhg5syZ7LXXXrz80kt885vf5MADD2SvvfbitNNOo6amhkWLFjFjxgymTp3KTTfdxE9/akeUc+bM4dhjj+15jubmeusIS4eajXHH4v8MTT5SW/+fuMr+2Nn2z7ZkLvx2LHzytBUSYG3IK16OR4EEOdje/GN8BGWMNT+sfDV5G5N1TGvmx222rhAAq424fPBg8vP6WfDn9Ou2xz2HpV/3T/taE05l6mVNU1I+LLh84rHJj8krhAe/2ra8uQ42LrHaxYqXdrxNkUYoaLuSXRvc31UyYVvcN3F7xP4da8cE3zMQp+ss6JVYXjERjvoFfPXO9M8di0LUIxTGHQ75JfY/8L97x/0j0L6PqhNQTWEnaYnGKC3Ma5M6+/LLL0/YHjt2LEcffXSb4y+99FIuvfTSjLZxh/jLsbD+Q7huK7TUWZt4zUZrZ+891Nb5xwWQX2Tt0BOPsw41CFafN3wMd33Ffj7zEfhysf38+u/a1t222nY0M+ZA43YYF5Dx9ZWbYLpjN8ZYdTuVMzOIiomwyWML37wsuN6XS9o/VygvPpp2mXkF/PvmjrWpQwh4s+y6JpyTb7fmG7+WMHgKbPgo+enKhgQLz/IRbctc8pKsHFf5XnzugCus+4xsGzbaHqc/YLW59nD9LAvute/7X2QFlhvi6hcKx/8B7pxJ2vjNmXnF9n8xcFLcsQ8w+VQ4qIP/ZxONawo/+ty2NVyQ3K+SYVRT2AmMMURihrz2Fs/taTx3rY2QScV6J7LitV/DL4fDzwfYiT9/2CNeZ9Fjccfkp/MSnXAL/hL/vPylxD/gw2fEP6cyZ7x7tw0B9Jp7vPjDJztKUSeuAhfUORaWtS3rLPa7IHkUyrB9YOq32pbn+3JoHe2be5DMNFE6MLgc2nZcrkN64X2OA95h8BS4/CMY1YEAiyNvhOHTbfhte5QkppJn5IGJ/g+/UKiYYN97DUgsLxtinfyTToav/DBenud7du6z/IpP8G5fF9y+Oa8Fl+8202oKrlAIO2bXvMLg+l2ACoWdIBozGGPID+1Cj3Hp0/D27YkRMqlw60WbU9eDRNX96StsjHi0xYYK7gzJRreLHtu58/pV/52hOWCWqqtR7d826GCnCYWxmkIAvQYEdyresl4D4EDfEullvtGwS0fs2Mk6s9JBVoid+zRc+j4cdVN838m3w7WVbY8JOVE8k06CwnYEuP8/mF+S6NfyDwDyCuDid+BbjyeWxyIw9UyroRz2U9jt4OD7coVCQamN5nLZ99z458s8IatBz/Y7L9p2mmj8/+VeJ9yOTy6D7EK9WWqMN0yvi4jG7DXDXaQppHWPtVVt46fn32YnBcWi8Xh0aDtz014kuNzLlpXw56Pab8tLN8LPd8KB7nYK/ghVOKlDAAAgAElEQVSajjL6kOBy2Ymf//g07n/KGXDmo3DAdzt27uvSWIO7oDSuKQzfL3FfcV8rNEKe0Mhv/DVRm3FHziGPBblscPC1gkbTfUYmaViS/0Ifjwmq/1g46BKYdhYM2MOGDwdpVW7bBkyEa9fY6KJkRH2mu1gkrrVAsF9i4O5ttSC/CdAVNn5N0O2884oSO/BhngCHfqPjwqxskHWYn+cJNhixn/2eXE1BQvF77kahkBU+haKiIjZv3kz//v2RLlyCMuZ00uEuuKaJxdi8eglFm5ZAbIIzUvSx4WO49xhrkrl+m52Is/LVeKjcfucn1r+xL3zrHzBggrXtv+9M0insnboxS+YmOmUzRVCMeUfZ63Q49f+sM/lXvo5sR763/uNslMneZ9pJUG4MeRChEEw8JnleHrB+h1gE5v/Jbh98ZfB363Lkz62D/uArrTN822o7onWjs468MX58XhE0O88wlJ/Y0exzjlOnOG7C65VEgOf7OsQBE+1I2v88IalMoHeAE/vk29qWJeAbBIXzIdlPwt+Zx1oSNQW/+cjF39nHfHnL3IFYm2g650bDBdbnsuGj+DP1csm78SAMdy5Jfklcu5CwDU2ONlkh5v4mu9F8lBVCYfjw4VRWVlJVlWa0TCfRFIlSVdNMbEsBhfmdvNJZLGp/IO5o1hiK1rzO8Pd/DcMGweq37A9n9b/htHvtrMhHPSGVf9ijbQjexsVtr/O3U9uWperoAF68vmP30tkc97u2TtRkzPqBfQ8ceSXpwcbMDo5kumIRlA52ZkiPsQnM/Hz1LnjywsSyZL6Fkgo40gm1dIXCoT8Nrusy03PNc5+GVW9CkbPoUlEfG9brklcY7/BDYRvhBXak75qO8j1CoSjJ4k3+Zyehjvtjyod3rD60nceRTFhe/LadFe1N2jfhmLi/C5L7RdoIBZ9wcdvgrbf3N+ODIgnByX+CRbNhxgVtzx+kfV1bGf9fh0KOptCcKHhUU9g58vPzGT16dPsVO5lXPvmSC+a+x5MXH8QeI5OMRHaUP+5lJ/Qc9Qtr+x57GDx2rd33wEmJdT9+wtrwvQTFZH/6bNuyrqLfmLYx9EGE8tvXECadnL5QGOiMyIL+ZF5N4dx5cN9x9vNZT8L/DEmcIQtxk0n/sU5BgDlv7zPaCgXvDNeE6weYr1JpCd9+vm17pn4zPpvYr/l4R5te02MsEq9bWBafrTtwku38xh5mAwda2x8gFJIhvvb3HWUnDu6I/8ZvLvVuTzsLPvhrvH2n3JkoFPIKEyfQ+U1srfXSFQqeZzn7Ghv88OL1UDrACsj9A7KbJsP7HYfy7MzmqqXQyyO41Kewa1LXbH9AvQozIFvdGZ7/+ik8faWNV05GuqacTZ6Qy8kBGkJ7JHNEpsNBl8GVaYR2ptN5JAuD9ON1AAZ1tl5b+aA9PXVDcRPapFOSn3/2Nem1IxlBbUpl0hp5QHC56/T0d9YJ28amyfDzTY+zvqSfzR00xTfPpE0HlaKNfq3omF/bd2/epmTMeTVxO9mMb0g0PeUV2bQhfrwzgYdMgR+44cee9vsd1H7fQ5CmEC6wGtnPNu98BJtXiHoFj184dSEqFHaC+iZrfywp6CTTUSxmTTwddZp7Z056//jeXD8AtZ7QPn+IXXuMmmW1Fpe9z4R9z0v/+HCBnRx10Ztw0p+S12tMI0+O9w+aLNQPUncqu58Ax3syaPptuO6xqcIxD7rU+hj8nHgLHPqT5Me5+EfVO0prp+3rrL33bwwMd+YxeCPJKsbZdBo3VHvs2T6hGwonzqxNpSkU9U508E48xp7bjcRKRYnPp9Hm+0vyv3Db6wYUXODMk/ELs3xHcCRr/1E3wbd9IbZBmkK4wD6rcCcMBr0DA68vLzDcumv8pSoUdoJWTWFnVkyLxaDaiW1+6xa446DEyTAdYepZMMSTmTLfN3qq/TL+udhjPz7t3vbPffbcRDPIMSnmOQTlinH/iIP3Su7QTIU3p5Dbjr2+bjNxTj4t+Bi/09DL6Q8mxu2HfULBTfeQV2gFz5UB/hiAc59pW7bvOXDIj5Jf2yVV5+oN2WwPd3TrH+H7O1VXC4u2Y54Lem7nvwzn/D/7OZV/oLAcrvo0+f5U+Dtxf/uTDZZcW/yZj9jvyY0AOvAS29FOcebFuJE9ybSxgy6xTnQv7rPw/j7aS+HSEbwDA6+WFSQUvn5f5103BVnhU+gu6p1keCWFOzDiq62y+eU3L29rH7//xB1r0KzvJ/6R/ELBjaUfPgMGeiahec0sXobuA184Kz6FQokhjoXlyVXcy96Hm/eOpzj2k8zGnorJp9oc9WD/1Fevik9OOu3PthP3O4e99+jHNRtc9KZdBczd7jsqsd4hV6eehNZepJbLteusj2LuZfCpI0i8o8TTH7DBAy4HXWL3P5eGiaqw1M6E9ZsyEjp3k75Q8D8DsM9n1CzrSN/jpLb7AfqPhxNvTh7p0x5+02FHNYWCkkQzUn4RXOsJZ3aFQmmS0Nsg3Ell3rala75MB6/5ynsN1682+TSbMnvoNNgzhSmzE1FNIU2aIzFGXfMMd7waX3qvvjlCOCQUhDvwGLevhy8/sXl+Hjyl/YVQOkJBr0Q11z+DFWxY6vkvxEdP7nHH/iax3rf/lZiUDuJ/qsF7OVETSYRCuLCtrdbL6EMSr/8zZ1Q+KCCxmkteEVyy0E44AicVgGdM48ape/Pyp5N/ZvBeNl4c7D1/58XE/e3NSvbG+c9I4WwsLLUakhttBIkj40knw7G/Tjxm/4vgh2k458H6A/w+igTzUSze6bTnyB88GX76pZ1ktv9FNh0IWGG89xnB9vuv/BAuXQAV49NrbxDtCYVTnO/T1bAOcQRmKM2xbV6BnSj37YCAiyBBCDbFNdiw01lXWe1jRwY1yfBqCt7n6qbKSDWwyRCqKaTB6s11HPLbVwH49XOf8N3ZNvqkrilKSUE4/bkR/3kUnvR1HCaFiSOIk261KZSDyC9ONEm0agqeHDlu2KG3Qy0oTfxTnPccjAxIGOYe42oM/hHnwD1tTqO8wtT28nA+nHSLTWHhbl+z1naSNyWZPZtXlNou7XZ0+50fT4vh79DPnts2csuL954vWZjepDlvR+zP1BqI57fSXoSJSHAHnDaekfWY2fZ6heVw+M+SHRAnr9BGWfkFVTIqJrZfpz38/yO/uWj346ygcr/XQ6+1r44wLSD9x7WViVqwF3dgVT48vefWUbwCzavZz7zCpir5/PXOv2Y7qFBIg5VVdQnb76/Zyj4j+1LfHOmYP2HhX9qvk4z+4+zIafcTUgiFEhI6HfcHXVgWn3tQHBCL7tUw8kviawT48f9x/GGv5z5tk5eFwrDbQbB0bvL78QuNonbMMO2NzlwB5fcNeBmTZGZzEBXj7Ks9Ojor2jsRLJ0R586EJroj7RNviY/Cr+1gQrp0SRVKu6MM26dtWWs4cCeSShs8+ymbwto/ga+z8IenuojYIIfWsq6blKvmo3ZYUVXLkvWJk7mu+rvNJFnXHE3Pn1C3Cd68eedy7VRMtKuHlficuAdeEv8czk+0d7baWj3XDZqglFcUj0bym4SuWBR3svo7Mb/DuKRffKnKr95lnZPJ6EgnMvnU9tMnu5pCOM+ahLqKjs6KLh8OM5x5DOl0+DvT2bpCIV3zys7Q2ULhquU2hXR303+szYWUKbx+n47OW8kQGf21iMgxwP8CYeAeY8yvfPtHAvcDfZw61xhj5rU5UTdy+O/bhjxuqLaTmqq2N7WvKax4xfoOwOZ52VG8edSnfyeet98/mgoafXqFQpCmIBIfCflNQt4cN/7R/Ym3wPRvt10AB6zZw9s2f+fZkc40nego16cQLrDRQt2QCyttdj/eLv3ZmbbpINxn0BVCwf/b6Ddmx+a1XLXcdoT+wU+24vXvBAqFdiKmMkDGNAURCQO3AccCk4AzRWSSr9pPgceMMdOAM4DbM9WezuCf37Oj4AmDymhojvL+mq0MLk+hVsZicYEA7ZtIknHi/ybmLTrhD7CHE6Hk/8Mn/HicTiGZpjDes75Dq4aRojN1z+2+F/extur26gOMOjh5vc7AnUjWZzfbqXRGDHlH2CvNJSDBY+rK8KzVVk0hQ6PN786Pf/b/Di/7AM7bgfFd6YDcEQiQOAhLJRSS+TwyQCb/OTOA5caYlQAi8ghwMuCd1moAt6csB76gBzNhUCmzJw5gS10z2xqaicQMsycOaFuxqdYuy+jNvQLJZx4fcLFNZ52M0sHJnXASggtft6kEXEYcAGvfjv/gvBPVvGGLZz4Sd3SnE2a3M6PvHcl90xH2PAX2TBICm2l+tqljE9FiXSUUMqwpDJpkZyqvW9gtZo6soD2h4Jpzd3RAuQNkUigMA7zhG5WAP6TlBuBfInIp0AsIWGILRGQOMAdg5MhkKXs7n1gssRMsyguTHw7RHImxvcF+WX2KPX/smg02TfVbt6R/kX5j7USwglK7UMhzASGqQX+41nA9gSF725eLO7nGzd3jPd5rPgqFaFUWg8JXO4tUoabZQEfNQKO/YsNyj/p5+sckTVWdAvc3kkkzVauvZxdbaKqn4M2vFSQUGh1/ZrrzYTqBTAqFoF+Jf6h5JnCfMeb3InIg8KCITDYmMUDZGHM3cDfA9OnTu8xYvL0xLsWvOmoCIWdOQks0Ro2zr6zI8wh/vwNhee4I4LCfWHPT+/fHl390l08MGlG6jyjoh+SWuTbdETPiC88n+3GllarXffQd6ACuXNy5K5ztLF/5kV3gvTsp6AXnpIjM8vP9pemtU+ynKxzNbuROS13qekow3vxMQf9lN2owSzSFSsC7uOtw2pqHvgMcA2CMmS8iRUAF8CU9gK31tuP/4zf25qvTrPkjPyy0RA01jVZTSBAKQRxytV3SMhnehUNCIbh4vl3sHOCU260ZKsge7zUf+XHLJhwDk79mlyasmGhNTEGOZuhYLiS/KWv/i+wi40GkMhvtc3Zyn0T5yHhSwM7ksDRyEvU00skbFESmfQoQH2Ts7NKouYp3xb6g//LYw+x70FoNGSKTQuE9YLyIjAbWYR3J3/TVWQMcDtwnInsARUDXLoqQgh8/sQiAPiXxkXq+oym4WkTv4nZU8/ZGeKlU+/IRcMQNwftSagrheJ3dDrKf2wurS8fEMGxfmwRvpm8dgXQnOPkJytrpcuUiuzhNeykZlOR0habgTnrsQkdoVtHUjlDoP9YmFOxCMvZrMcZEROQS4HlsuOm9xpjFInIjsMAYMxf4AfB/InIl1jZxrumOdTWTMH/lZgD6eYVCnisU0tQUCndCKKQ06biaQoAp5+ibrK3SnTOQDu55UuWFCYVtbpuuIpeiUDJCF4Skzvq+XWpyryRJCZXUeDWFHrLWe0bj9pw5B/N8Zdd5Pi8BOtBzdR1Rj5N5iCfstMBxNLs+hd5FTqfuJs7yU9Be7pwAodB7OGyvTD0794SbrVlqzOy2+wZMtLOLO8p5z9l1ZbuT772bOuW1kj5doSmE8xMXq1c6xnG/hYedPGA7s2Z4J9IzWtEDaY7EO6aBveNCwetTKAiHKMxzHuE2J9Dq+D/Aj9fHfQXtJVQLiqc//wWb2jnVyKHPCLsMYGdGlux2YPLF27uKARO7JQlYVtMVk9eUHWPisfEV9cbM7s6WtKK/liS4QuFnJyTOt2v1KTS0UFaUZ5PhrXkbnv+xrTBmtp3NW9zXRmS0Zz4K+sP2HgqTUiRuU5SOoHMIejYjD4CfbMxcfqUOokIhCU1RO6mrIC9xtJ4fDhGJGbY3RuL+hHs9M4NL+tt3VxVsz9GsDjol06im0PPpIQIB1HyUFFdTKPStlVCUb0ddX25vDI48al3yz3Hc+pPg+R25XZ2OQck9VCgoHUCFQhJcoeDXFEqdrKgbtjcGRx65Nv7WPEG+R3zZB3DoT+PrAw8NSA+sKJ2JCgWlA6hQSEJzNIlQcATB+m2N8cgjL64wOOB7zgED4WhnPePiftbfcMgPbYK7775ls4wqSiZRn4LSAXQIkYRWTSHs1xSsIGiOxlLPUdh/jn1BPO21X2sYtGentFVRUqKagtIBVFNIQjLzUS/PojqBmkIQrelvdcSmdAMqFJQOoEIhCYFCIRajV158Utu+u/VN72SuhtBDJqcoOYYKBaUD6K8lCfXNNiS12Ik2onIB3HM4ewMXHvI2YytKOXrPNCd6uRpCR3LuK0pnoUJB6QD6a0lCTZMnNfbLv4DXf9u679rDRrQ/KS2IHpLbRMkx1GypdADtpZJQ25rwLj9BIABQv7ljJ2vNaKp/TqUbUE1B6QAqFJKQMgtqsuR3yYilSHOtKJlGhYLSAfTXkoSaxgj5YYknvPPiXUIvHfqNsYtk7H9R5zROUTqCCgWlA+ivJQnbG1voXZRvE9758WoK6Sz/EArBSR1Yt1lROhPVUJUOoL+WJGyqaaJ/qbO4jj+pnVdT6KgpSVG6mqCBjaIkQYVCEjbXNVNR6ixy06sicedLN8Y/Rxq6rlGKoigZRoVCEjbVNsWFQsy3Eljlu/HPqikoipJFqFBIQoL5KBZJXrGjTmdF6SpmXg7hgvbrKYoHFQoBNDRHqWuOxjUFE01eWTUFpady5I3ws6ruboWyi6FCIYBNtbajH9BqPlJNQVGU3ECFQgAbt9uOfkBvVyj4NIWRB8U/t6ijWVGU7EGFQgBrttQDMLKfs7SmXyh4c8k0bo9/Luyd4ZYpiqJkFp28FsC6rXb0P7xvsS1I5VNorLbvMy6EGRdkuGWKoiiZRYVCAFvrWygtzKMwz9EI/D4F4wlRbdxm379ylV16U1EUZRdGzUcBVDe0UF7sWVXNaz4auk9iagtXU1DTkaIoWYAKhQCqG5rp7QqFvxyXaD4qLAU8QqFhK+QVQ35Rl7ZRURQlE6hQCMBqCo5lbfW/fXsl0XxUswHKBnVZ2xRFUTKJCoUA6pqi9CrwuVsO/j5ctcwmF/Oaj2o2QGmay3IqiqL0cFQoBNAUiVKU71slrai3dSRLiATzUf3mtgnzFEVRdlFUKATQFIm1XVyndaESn/ko2gx5hV3WNkVRlEyiQiGA5kiMwnzfo3HXV/abj6ItEMpHURQlG0hLKIjIP0TkeJGOLeEkIseIyKcislxErklS53QRWSIii0XkoY6cP1M0RWIUhFNoCl7zUawFwioUFEXJDtLt5O8AvgksE5Fficju7R0gImHgNuBYYBJwpohM8tUZD1wLzDTG7Alc0ZHGZ4qmSJRCv08h5DwqCbXVFFQoKIqSJaQlFIwxLxpjvgXsA6wCXhCRt0TkPBFJ1iPOAJYbY1YaY5qBR4CTfXUuAG4zxmx1rvPljtxEZ2KMseajZD4F8fsU1HykKEr2kLY5SET6A+cC5wMfAP+LFRIvJDlkGLDWs13plHmZAEwQkX+LyNsickySa88RkQUisqCqKnP54Y0xfLKhhpihrfnI9Smo+UhRlCwmrdxHIvIEsDvwIHCiMWa9s+tREVmQ7LCAMuPbzgPGA7OB4cAbIjLZGLMt4SBj7gbuBpg+fbr/HJ3GA/NXc/3cxQBtHc1uZlQJJd6Fmo8URcki0k2I9ydjzMtBO4wx05McUwmM8GwPB74IqPO2MaYF+FxEPsUKiffSbFen8p/KuCxqoym4yxp6zUfGWE1BzUeKomQJ6ZqP9hCRPu6GiPQVkYvbOeY9YLyIjBaRAuAMYK6vzj+BQ51zVmDNSSvTbFOnE5a4crP3iD6JO/NLPBuOquBmT9V1cBVFyRLSFQoXeE06jmM45eIBxpgIcAnwPLAUeMwYs1hEbhSRk5xqzwObRWQJ8ArwQ2PM5o7eRGcR8giFaSP7Ju50E955o4+iLfY9rBnIFUXJDtLtzUIiIsbY3tAJN213eGyMmQfM85Vd5/lsgO87r24nHA5ygzjkOQvueM1HMUcoqPlIUZQsIV2h8DzwmIjcibWdXAQ8l7FWdRNe81EbWlNje6KPWjUFNR8pipIdpCsUrgYuBL6L7RX/BdyTqUZ1F+FQCqEQdvIbedNcqPlIUZQsI63ezBgTw85qviOzzeleXJ/C5GHOKmotDfGdbtipN0uqmo8URcky0p2nMB74JTZdResSY8aYMRlqV7cQczSAB769vy14+RfxnUFZUhsc33uRLsWpKEp2kG700V+wWkIEG0L6AHYiW1bRFIlRUVpIv16Oj6DeEwjlrpngNR/VbrTvZUO6rpGKoigZJF2hUGyMeQkQY8xqY8wNwGGZa1b30NgSpcg7k7nXAPte3A8Ky+xnr/moZoN9L9XlOBVFyQ7S9ZA2Ommzl4nIJcA6YGDmmtU9bG9ooXeRxz/Qdzf7foY3o7fHfNTomI+KfXMaFEVRdlHS1RSuAEqAy4B9gbOAczLVqO5ie2ML5cUeoRBzOv+KCfEykXjuo2izfdeV1xRFyRLa1RSciWqnG2N+CNQC52W8Vd3E9oYIoyo86SzcNBYh79oKnnkKEUcoaPSRoihZQruagjEmCuwrkmpmV3ZQ7TcftQoFj+yUUNx8FG22AiGkq5oqipIdpOtT+AB4SkT+DtS5hcaYJzLSqm6gJRpjU20TA8o8pqBAoYBn8lqzzmZWFCWrSFco9AM2kxhxZICsEQqrN9cRiRnGDSyNF8ai9t0rFBLSXDTrWgqKomQV6c5ozlo/gktVjfUPDC4vihcG+RQSsqQ2q5NZUZSsIt0ZzX+h7appGGO+3ekt6iYaI1YrKMr3CIBYxC7D6XWneLOkRlvUfKQoSlaRrvnoac/nIuCrtF1FbZemqcURCnk+oRDyPyJv9FGTmo8URckq0jUf/cO7LSIPAy9mpEXdRFPEjv4TZjQHCQW/+Sis5iNFUbKHHY2lHA+M7MyGdDeNjqZQmGA+igYIBUkMSVVNQVGULCJdn0INiT6FDdg1FrKGxhZHU8jzawphX01f9JE6mhVFySLSNR+VZboh3U1TJEhTCDIf+RbZaeNzUBRF2XVJy3wkIl8VkXLPdh8ROSVzzep6kmsKAT6F1kV2AsxLiqIouzDp+hSuN8ZUuxvGmG3A9ZlpUvfQ2BIlLyTkhb1CIajT92gKgdFJiqIouy7pCoWgelnVG9Y3Ryku8PkPgnwKokJBUZTsJV2hsEBE/iAiY0VkjIj8EViYyYZ1JQtWbeG+t1ZRkpZQ8JqPVCgoipJdpCsULgWagUeBx4AG4HuZalRXc91TiwHYuL0pcUdLA+QXtz3ADUmNRQOikxRFUXZd0o0+qgOuyXBbuo1xA0tZsn572x3NtVBQmljWsA1a6mHjEjAqFBRFyS7SjT56QUT6eLb7isjzmWtW1zKod5K5Bs11bYXCsn/Z93/frOYjRVGyjnTNRxVOxBEAxpitZNEazc1Oiov7vz3Dt6MWCnollhk3nXa+CgVFUbKOdIVCTERa01qIyCgCsqbuqjRFYgwsK+SQCQMSdwRpCq1rLIR1noKiKFlHuj3aT4A3ReQ1Z/srwJzMNKnraWyJJqbMdmmqhcIkQiHsaAqiS3EqipI9pNWjGWOeA6YDn2IjkH6AjUDKCpoiMQrdmczrP4LHvw3RiHUo5xUlVjae1dhUU1AUJctINyHe+cDlwHDgQ+AAYD6Jy3PusiRoCncfYkNOj7zRagL+LKjeJTrVp6AoSpaRru3jcmA/YLUx5lBgGlCVsVZ1MQmagjsHwcQAYx3KXlqX6FRNQVGU7CNdodBojGkEEJFCY8wnwMT2DhKRY0TkUxFZLiJJ5zmIyGkiYkRkeprt6VQCfQoRu2YzYV+nb3w+BZ2noChKFpHuMLfSmafwT+AFEdlKO8txikgYuA04EqgE3hORucaYJb56ZcBlwDsdbXxn0dgSo18vn3yMOrOb/ZqCy/YvoKUurjkoiqJkAenOaP6q8/EGEXkFKAeea+ewGcByY8xKABF5BDgZWOKr93PgN8BV6Ta6s2mKRCnM84347zjIvidbWe3Dv9n3la9mrF2KoihdTYfjKY0xrxlj5hpjmtupOgxY69mudMpaEZFpwAhjzNOpTiQic0RkgYgsqKrqfFdGY0uMwvwkj6I9n4HreFYURckCMhlkLwFlrRPeRCQE/BEb3poSY8zdxpjpxpjpAwYMaK96h7GO5iS+Ab+mcO48X+Nind4eRVGU7iKTQqESGOHZHk6iH6IMmAy8KiKrsGGuc7vD2dzUEqUoXU1h8OTEbaOagqIo2UMmhcJ7wHgRGS0iBcAZwFx3pzGm2hhTYYwZZYwZBbwNnGSMWZDBNrUhGjPUNEWSawp+R7P46vUZiaIoSraQMaFgjIkAlwDPA0uBx4wxi0XkRhE5KVPX7Sj3vLESgOVf1gRX8Iek+tNanHZf5zdKURSlm8jozCtjzDxgnq/suiR1Z2eyLcn4dKMVBh9VVgdXaKMpeIRC2RDo1T9DLVMURel6cj6b2/iBZQD85Pg9giv4Hc3eyWpBq7IpiqLswuS8UBAnRurISYOCK6TSFPJ9ay0oiqLs4uS8UGhqsSGlBeEkjyKVT0E1BUVRsgwVCpEoeSEhL5lQaKMpCK1TMFQoKIqSZeS8UGj2ZkgNImhGs+tXyC/JTKMURVG6iZwXCk2RGIVBq665+M1HEDchqaagKEqWoUIhEm1HUwhIiCeqKSiKkp2oUIjEKEglFIKypKqmoChKlpLzQqGhOUpRshQXkERTUKGgKEp2kvNCobqhhfLiJGsmQLBPwV1Yp6h3ZhqlKIrSTahQaGihdyqhEKQpRBrse2F5ZhqlKIrSTeS0UNhU28QnG2owxiSvlGqRncKyzm+UoihKN5LTQuHFJRsBeOmTL5NXSrYcJ6j5SFGUrCOnhUJpkdUCbjlzWvJKqTSFgtJObpGiKEr3ktNCodHJe7T38BS+gVSaQl5RJ7dIURSle8lxoWCX0ixKNaM5yNHcui+jy1EoiqJ0OTktFJoiVlNIPU9hB/cpiqLsguS0UHA1hcL8FI/BXXAhCBUKiqJkGTktFJpaooiQOvdRKtR8pChKlpHTvQGsC1IAAAyTSURBVNotLy8HQFJpA6lQoaAoSpaRs5rCms31O38SNR8pipJl5KxQ+LKmEYALZo3e8ZOopqAoSpaRs0Khvtk6mY/ac/COn0RUU1AUJbvIeaFQnGqOQnuopqAoSpaRs0KhocWmvy4p8AiFxuqOnUSFgqIoWUbOCgVXUygp8HTstx/YsZOoo1lRlCwjZ4VCg2s+cjWFz56H7es6dhIVCoqiZBk5KxTimkIYKhfAQ6d3/CRqPlIUJcvIWaEwb9F6APLDIWjavmMnUaGgKEqWkZNCYfmXtXyyoSZeEC5MrLDfBemdSENSFUXJMnJSKNQ3RxIL/GsmlA5K70ShnHx8iqJkMTnZq6VakhmAgpIuaYeiKEpPI6NCQUSOEZFPRWS5iFwTsP/7IrJERD4SkZdEZLdMtselwUmZ3UrMrzkUdEUzFEVRehwZEwoiEgZuA44FJgFnisgkX7UPgOnGmCnA48BvMtUeL244ait+oSA5qUApiqJkVFOYASw3xqw0xjQDjwAneysYY14xxrjpSt8GhmewPa3U+4VCtCVxuz2hMPG4zm2QoihKDyGTMZXDgLWe7Upg/xT1vwM8G7RDROYAcwBGjhy50w1zHc1//MbetiDmExLtCYVv/LWtIFEURckCMikUglauCXTxishZwHTgkKD9xpi7gbsBpk+f3p6buF1cn8LB4wbYgpivgw+FofdwmHB08AlCYZ3NrChKVpJJoVAJjPBsDwe+8FcSkSOAnwCHGGOaMtieVhJmM0OwT+H7i7uiKYqiKD2KTPoU3gPGi8hoESkAzgDmeiuIyDTgLuAkY8yXGWxLAm3SZvtNQYOndFVTFEVRehQZEwrGmAhwCfA8sBR4zBizWERuFJGTnGq/BUqBv4vIhyIyN8npOpWG5ghF+SFCIcfC5fUpnHIHDJ7cFc1QFEXpcWQ0eY8xZh4wz1d2nefzEZm8fjLqm6OJKbO9PoWSiq5vkKIoSg8h5wLyN9c28bd31hAOefzgT30v/jm/qOsbpSiK0kPIOaFw9xsrAaiqSeLTzivuwtYoiqL0LHJOKFT0KkxdIa+d/YqiKFlMzgmFsiLrS7jvvP2CK+SrpqAoSu6Sc0KhORoDYPKwclsQaU6soJqCoig5TO4JhYgVCvlh59brfNMj1KegKEoOk3tCwdEUCvOcW//rqYkVNPpIUZQcJueEQkvEpk7KD4fsajtVnyRWyFOhoChK7pJzQqE5GiUcEjtPwU1vMeGYeAX/0pyKoig5REZnNPdEmiMxClx/QtSZqzDqYNjr6/Dh37qvYYqiKD2AnBMKLVFDftiZzRxxhEK4EPY6zb4URVFymJwTCve9tSq+EWm07xqGqiiKAuSYT6HFiTxqxdUU1LmsKIoC5JhQqNzaAMDMcf1twZMX2fe8gm5qkaIoSs8ip4TCF9usULj0sPG2oPJd+66agqIoCpBjQmFbvQ1B7Vvi0wzUp6AoigLkmFC48rEPASgvzofG7fEdYRUKiqIokGNCwc171Efq4Fcj4jsG7tFNLVIURelZ5JRQcCna/nl8Y9ZVUNKv+xqjKIrSg8g5oXDoxAEgnqU4m2u7rzGKoig9jJwRCrGYTYQ3ZXgfaNga3zFocje1SFEUpeeRM0KhoSUKQO9wc2K67GlndVOLFEVReh45IxTqm61QGNb4WeIOrylJURQlx8mZ3Ee1TRHODz/DMe9qJlRFUZRk5Iym8M8P1vHTfJ9A+P7S7mmMoihKDyVnhMLZB4xMLDj1z9B7aPc0RlEUpYeSM0Khf7g+sUDXTlAURWlDzggF3r7dvk/7L7hkQfe2RVEUpYeSM45mdj8Bmmph1g+gdEB3t0ZRFKVHkjtCYehU+1IURVGSkjvmI0VRFKVdVCgoiqIorWRUKIjIMSLyqYgsF5FrAvYXisijzv53RGRUJtujKIqipCZjQkFEwsBtwLHAJOBMEZnkq/YdYKsxZhzwR+DXmWqPoiiK0j6Z1BRmAMuNMSuNMc3AI8DJvjonA/c7nx8HDhfRZESKoijdRSaFwjBgrWe70ikLrGOMiQDVQH//iURkjogsEJEFVVVVGWquoiiKkkmhEDTiNztQB2PM3caY6caY6QMG6BwDRVGUTJFJoVAJeBZCZjjwRbI6IpIHlANbMtgmRVEUJQWZnLz2HjBeREYD64AzgG/66swFzgHmA6cBLxtj2mgKXhYuXLhJRFbvYJsqgE07eOyuit5zbqD3nBvszD3vlk6ljAkFY0xERC4BngfCwL3GmMUiciOwwBgzF/gz8KCILMdqCGekcd4dth+JyAJjzPQdPX5XRO85N9B7zg264p4zmubCGDMPmOcru87zuRH4eibboCiKoqSPzmhWFEVRWsk1oXB3dzegG9B7zg30nnODjN+ztOPXVRRFUXKIXNMUFEVRlBSoUFAURVFayRmh0F7G1l0VERkhIq+IyFIRWSwilzvl/UTkBRFZ5rz3dcpFRG5xnsNHIrJP997BjiEiYRH5QESedrZHO5l2lzmZdwuc8qzIxCsifUTkcRH5xPmuD8yB7/hK5zf9sYg8LCJF2fg9i8i9IvKliHzsKevwdysi5zj1l4nIOTvanpwQCmlmbN1ViQA/MMbsARwAfM+5t2uAl4wx44GXnG2wz2C885oD3NH1Te4ULgeWerZ/DfzRud+t2Ay8kD2ZeP8XeM4YszuwN/bes/Y7FpFhwGXAdGPMZOxcpzPIzu/5PuAYX1mHvlsR6QdcD+yPTUZ6vStIOowxJutfwIHA857ta4Fru7tdGbrXp4AjgU+BIU7ZEOBT5/NdwJme+q31dpUXNmXKS8BhwNPYHFqbgDz/942dPHmg8znPqSfdfQ8dvN/ewOf+dmf5d+wmy+znfG9PA0dn6/cMjAI+3tHvFjgTuMtTnlCvI6+c0BRIL2PrLo+jMk8D3gEGGWPWAzjvA51q2fAsbgZ+BMSc7f7ANmMz7ULiPaWVibeHMwaoAv7imMzuEZFeZPF3bIxZB/wOWAOsx35vC8nu79lLR7/bTvvOc0UopJWNdVdGREqBfwBXGGO2p6oaULbLPAsROQH40hiz0FscUNWksW9XIQ/YB7jDGDMNqCNuTghil79nx/RxMjAaGAr0wppO/GTT95wOye6z0+4/V4RCOhlbd1lEJB8rEP5mjHnCKd4oIkOc/UOAL53yXf1ZzAROEpFV2IWbDsNqDn2cTLuQeE/ZkIm3Eqg0xrzjbD+OFRLZ+h0DHAF8boypMsa0AE8AB5Hd37OXjn63nfad54pQaM3Y6kQrnIHN0LrLIyKCTSy41BjzB88uNwMtzvtTnvKznSiGA4BqV03dFTDGXGuMGW6MGYX9Hl82xnwLeAWbaRfa3q/7HNLKxNvTMMZsANaKyESn6HBgCVn6HTusAQ4QkRLnN+7ec9Z+zz46+t0+DxwlIn0dLesop6zjdLeDpQsdOccBnwErgJ90d3s68b4OxqqJHwEfOq/jsPbUl4Blzns/p75gI7FWAIuw0R3dfh87eO+zgaedz2OAd4HlwN+BQqe8yNle7uwf093t3sF7nQoscL7nfwJ9s/07Bv4b+AT4GHgQKMzG7xl4GOs3acGO+L+zI98t8G3n/pcD5+1oezTNhaIoitJKrpiPFEVRlDRQoaAoiqK0okJBURRFaUWFgqIoitKKCgVFURSlFRUKitKFiMhsN7OrovREVCgoiqIorahQUJQAROQsEXlXRD4Ukbuc9RtqReT3IvK+iLwkIgOculNF5G0nv/2Tntz340TkRRH5j3PMWOf0/7+9+2eNIorCMP68IgQlopWNhWAXBP/EUqz8AhZKQAnB2sZOhNj4HQQtE5JCBO0Fi4VUimJlaZVeBItYxGNx7w5xA4kEEhd8ftXu5e5lbjF7ZgbmPbM7eiOs9zd2palgUZAmJJkDFoDrVXUF2Abu0ULZPlXVPDCi5dcDrAKPquoS7S3T8fg68KyqLtNye8ZRE1eBh7TeHhdoeU7SVDi+/xTpv3MTuAZ86BfxJ2iBZL+Al33OGvA6yWngTFWN+vgK8CrJKeBcVb0BqKotgL7e+6ra7N8/07L0Nw5/W9L+LArSbgFWqurxH4PJk4l5e2XE7PVI6OeOz9t4HmqK+PhI2u0dcDvJWRj65Z6nnS/jhM67wEZVfQe+JbnRxxeBUbWeFptJbvU1ZpKcPNJdSAfgFYo0oaq+JFkG3iY5RkuvfEBrbnMxyUdaZ6+F/pMl4Hn/0/8K3O/ji8CLJE/7GneOcBvSgZiSKv2lJD+qavZfH4d0mHx8JEkaeKcgSRp4pyBJGlgUJEkDi4IkaWBRkCQNLAqSpMFvlR58Iu89X3AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:40:24.812788Z",
     "start_time": "2020-06-13T11:39:59.534330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on first 10000 benign test samples: 0.858900\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "y_pred = model2.predict(x_test[:n])\n",
    "accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test[:n], axis=1))\n",
    "print(\"Accuracy on first %i benign test samples: %f\" % (n, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
